// Code generated by protoc-gen-gogo. DO NOT EDIT.
// source: src/api/corepb/v1/model_exec.proto

package corepb

import (
	fmt "fmt"
	proto "github.com/gogo/protobuf/proto"
	framework "github.com/google/mediapipe/mediapipe/framework"
	io "io"
	math "math"
	math_bits "math/bits"
	reflect "reflect"
	strings "strings"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.GoGoProtoPackageIsVersion3 // please upgrade the proto package

type ExecutionSpec struct {
	Graph *framework.CalculatorGraphConfig `protobuf:"bytes,1,opt,name=graph,proto3" json:"graph,omitempty"`
}

func (m *ExecutionSpec) Reset()      { *m = ExecutionSpec{} }
func (*ExecutionSpec) ProtoMessage() {}
func (*ExecutionSpec) Descriptor() ([]byte, []int) {
	return fileDescriptor_2eacf87cbdc6b8b6, []int{0}
}
func (m *ExecutionSpec) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *ExecutionSpec) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_ExecutionSpec.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *ExecutionSpec) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ExecutionSpec.Merge(m, src)
}
func (m *ExecutionSpec) XXX_Size() int {
	return m.Size()
}
func (m *ExecutionSpec) XXX_DiscardUnknown() {
	xxx_messageInfo_ExecutionSpec.DiscardUnknown(m)
}

var xxx_messageInfo_ExecutionSpec proto.InternalMessageInfo

func (m *ExecutionSpec) GetGraph() *framework.CalculatorGraphConfig {
	if m != nil {
		return m.Graph
	}
	return nil
}

type ModelSpec struct {
	OnnxBlobKey  string             `protobuf:"bytes,1,opt,name=onnx_blob_key,json=onnxBlobKey,proto3" json:"onnx_blob_key,omitempty"`
	TensorrtSpec *TensorRTModelSpec `protobuf:"bytes,100,opt,name=tensorrt_spec,json=tensorrtSpec,proto3" json:"tensorrt_spec,omitempty"`
}

func (m *ModelSpec) Reset()      { *m = ModelSpec{} }
func (*ModelSpec) ProtoMessage() {}
func (*ModelSpec) Descriptor() ([]byte, []int) {
	return fileDescriptor_2eacf87cbdc6b8b6, []int{1}
}
func (m *ModelSpec) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *ModelSpec) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_ModelSpec.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *ModelSpec) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ModelSpec.Merge(m, src)
}
func (m *ModelSpec) XXX_Size() int {
	return m.Size()
}
func (m *ModelSpec) XXX_DiscardUnknown() {
	xxx_messageInfo_ModelSpec.DiscardUnknown(m)
}

var xxx_messageInfo_ModelSpec proto.InternalMessageInfo

func (m *ModelSpec) GetOnnxBlobKey() string {
	if m != nil {
		return m.OnnxBlobKey
	}
	return ""
}

func (m *ModelSpec) GetTensorrtSpec() *TensorRTModelSpec {
	if m != nil {
		return m.TensorrtSpec
	}
	return nil
}

type TensorRTModelSpec struct {
	OptimizationProfile []*TensorRTOptimizationProfile `protobuf:"bytes,1,rep,name=optimization_profile,json=optimizationProfile,proto3" json:"optimization_profile,omitempty"`
	EngineBlobKey       string                         `protobuf:"bytes,2,opt,name=engine_blob_key,json=engineBlobKey,proto3" json:"engine_blob_key,omitempty"`
}

func (m *TensorRTModelSpec) Reset()      { *m = TensorRTModelSpec{} }
func (*TensorRTModelSpec) ProtoMessage() {}
func (*TensorRTModelSpec) Descriptor() ([]byte, []int) {
	return fileDescriptor_2eacf87cbdc6b8b6, []int{2}
}
func (m *TensorRTModelSpec) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *TensorRTModelSpec) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_TensorRTModelSpec.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *TensorRTModelSpec) XXX_Merge(src proto.Message) {
	xxx_messageInfo_TensorRTModelSpec.Merge(m, src)
}
func (m *TensorRTModelSpec) XXX_Size() int {
	return m.Size()
}
func (m *TensorRTModelSpec) XXX_DiscardUnknown() {
	xxx_messageInfo_TensorRTModelSpec.DiscardUnknown(m)
}

var xxx_messageInfo_TensorRTModelSpec proto.InternalMessageInfo

func (m *TensorRTModelSpec) GetOptimizationProfile() []*TensorRTOptimizationProfile {
	if m != nil {
		return m.OptimizationProfile
	}
	return nil
}

func (m *TensorRTModelSpec) GetEngineBlobKey() string {
	if m != nil {
		return m.EngineBlobKey
	}
	return ""
}

type TensorRTOptimizationProfile struct {
	TensorShapeRange []*TensorRTTensorShapeRange `protobuf:"bytes,1,rep,name=tensor_shape_range,json=tensorShapeRange,proto3" json:"tensor_shape_range,omitempty"`
}

func (m *TensorRTOptimizationProfile) Reset()      { *m = TensorRTOptimizationProfile{} }
func (*TensorRTOptimizationProfile) ProtoMessage() {}
func (*TensorRTOptimizationProfile) Descriptor() ([]byte, []int) {
	return fileDescriptor_2eacf87cbdc6b8b6, []int{3}
}
func (m *TensorRTOptimizationProfile) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *TensorRTOptimizationProfile) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_TensorRTOptimizationProfile.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *TensorRTOptimizationProfile) XXX_Merge(src proto.Message) {
	xxx_messageInfo_TensorRTOptimizationProfile.Merge(m, src)
}
func (m *TensorRTOptimizationProfile) XXX_Size() int {
	return m.Size()
}
func (m *TensorRTOptimizationProfile) XXX_DiscardUnknown() {
	xxx_messageInfo_TensorRTOptimizationProfile.DiscardUnknown(m)
}

var xxx_messageInfo_TensorRTOptimizationProfile proto.InternalMessageInfo

func (m *TensorRTOptimizationProfile) GetTensorShapeRange() []*TensorRTTensorShapeRange {
	if m != nil {
		return m.TensorShapeRange
	}
	return nil
}

type TensorRTTensorShapeRange struct {
	TensorName string  `protobuf:"bytes,1,opt,name=tensor_name,json=tensorName,proto3" json:"tensor_name,omitempty"`
	Dim        []int32 `protobuf:"varint,2,rep,packed,name=dim,proto3" json:"dim,omitempty"`
}

func (m *TensorRTTensorShapeRange) Reset()      { *m = TensorRTTensorShapeRange{} }
func (*TensorRTTensorShapeRange) ProtoMessage() {}
func (*TensorRTTensorShapeRange) Descriptor() ([]byte, []int) {
	return fileDescriptor_2eacf87cbdc6b8b6, []int{4}
}
func (m *TensorRTTensorShapeRange) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *TensorRTTensorShapeRange) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_TensorRTTensorShapeRange.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *TensorRTTensorShapeRange) XXX_Merge(src proto.Message) {
	xxx_messageInfo_TensorRTTensorShapeRange.Merge(m, src)
}
func (m *TensorRTTensorShapeRange) XXX_Size() int {
	return m.Size()
}
func (m *TensorRTTensorShapeRange) XXX_DiscardUnknown() {
	xxx_messageInfo_TensorRTTensorShapeRange.DiscardUnknown(m)
}

var xxx_messageInfo_TensorRTTensorShapeRange proto.InternalMessageInfo

func (m *TensorRTTensorShapeRange) GetTensorName() string {
	if m != nil {
		return m.TensorName
	}
	return ""
}

func (m *TensorRTTensorShapeRange) GetDim() []int32 {
	if m != nil {
		return m.Dim
	}
	return nil
}

func init() {
	proto.RegisterType((*ExecutionSpec)(nil), "gml.internal.api.core.v1.ExecutionSpec")
	proto.RegisterType((*ModelSpec)(nil), "gml.internal.api.core.v1.ModelSpec")
	proto.RegisterType((*TensorRTModelSpec)(nil), "gml.internal.api.core.v1.TensorRTModelSpec")
	proto.RegisterType((*TensorRTOptimizationProfile)(nil), "gml.internal.api.core.v1.TensorRTOptimizationProfile")
	proto.RegisterType((*TensorRTTensorShapeRange)(nil), "gml.internal.api.core.v1.TensorRTTensorShapeRange")
}

func init() {
	proto.RegisterFile("src/api/corepb/v1/model_exec.proto", fileDescriptor_2eacf87cbdc6b8b6)
}

var fileDescriptor_2eacf87cbdc6b8b6 = []byte{
	// 466 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0x84, 0x52, 0x4f, 0x6f, 0xd3, 0x3e,
	0x18, 0x8e, 0x57, 0xed, 0x27, 0xcd, 0xfd, 0x55, 0x8c, 0xc0, 0x21, 0x02, 0xc9, 0x54, 0x11, 0x42,
	0x95, 0x10, 0x8e, 0x56, 0x04, 0x17, 0x6e, 0x9b, 0xd0, 0x0e, 0x68, 0x30, 0x65, 0x3b, 0x71, 0x09,
	0x4e, 0xfa, 0x36, 0xb5, 0xe6, 0xd8, 0x96, 0xe3, 0x8d, 0x8e, 0x0b, 0xf0, 0x0d, 0xf8, 0x12, 0x48,
	0x7c, 0x14, 0x8e, 0x3d, 0xee, 0x48, 0xd3, 0x0b, 0xc7, 0x7d, 0x04, 0xe4, 0xb8, 0x2b, 0x88, 0x6a,
	0xec, 0x14, 0xbf, 0x8f, 0x9e, 0x3f, 0xef, 0xa3, 0xbc, 0x38, 0xae, 0x4d, 0x91, 0x30, 0xcd, 0x93,
	0x42, 0x19, 0xd0, 0x79, 0x72, 0xb6, 0x93, 0x54, 0x6a, 0x04, 0x22, 0x83, 0x29, 0x14, 0x54, 0x1b,
	0x65, 0x55, 0x18, 0x95, 0x95, 0xa0, 0x5c, 0x5a, 0x30, 0x92, 0x09, 0xca, 0x34, 0xa7, 0x8e, 0x4c,
	0xcf, 0x76, 0xee, 0x3d, 0xac, 0x60, 0xc4, 0x99, 0xe6, 0x1a, 0x92, 0xb1, 0x61, 0x15, 0xbc, 0x57,
	0xe6, 0x24, 0x29, 0x98, 0x28, 0x4e, 0x05, 0xb3, 0xca, 0x78, 0x7d, 0xbc, 0x8f, 0x7b, 0x2f, 0xa7,
	0x50, 0x9c, 0x5a, 0xae, 0xe4, 0x91, 0x86, 0x22, 0x7c, 0x8e, 0x37, 0x4b, 0xc3, 0xf4, 0x24, 0x42,
	0x7d, 0x34, 0xe8, 0x0e, 0xfb, 0x74, 0x65, 0x43, 0xf7, 0x56, 0xe2, 0x7d, 0xc7, 0xd8, 0x53, 0x72,
	0xcc, 0xcb, 0xd4, 0xd3, 0xe3, 0xcf, 0x08, 0x6f, 0x1d, 0xb8, 0xed, 0x5a, 0x97, 0x18, 0xf7, 0x94,
	0x94, 0xd3, 0x2c, 0x17, 0x2a, 0xcf, 0x4e, 0xe0, 0xbc, 0x75, 0xdb, 0x4a, 0xbb, 0x0e, 0xdc, 0x15,
	0x2a, 0x7f, 0x05, 0xe7, 0xe1, 0x21, 0xee, 0x59, 0x90, 0xb5, 0x32, 0xc6, 0x66, 0xb5, 0x86, 0x22,
	0x1a, 0xb5, 0x89, 0x8f, 0xe9, 0x75, 0x95, 0xe8, 0x71, 0x4b, 0x4f, 0x8f, 0x57, 0x39, 0xe9, 0xff,
	0x57, 0x0e, 0x6e, 0x8a, 0xbf, 0x22, 0x7c, 0x7b, 0x8d, 0x13, 0x4e, 0xf0, 0x5d, 0xa5, 0x2d, 0xaf,
	0xf8, 0x07, 0xe6, 0x5a, 0x66, 0xda, 0xa8, 0x31, 0x17, 0x10, 0xa1, 0x7e, 0x67, 0xd0, 0x1d, 0x3e,
	0xbb, 0x39, 0xee, 0xcd, 0x1f, 0xea, 0x43, 0x2f, 0x4e, 0xef, 0xa8, 0x75, 0x30, 0x7c, 0x84, 0x6f,
	0x81, 0x2c, 0xb9, 0x84, 0xdf, 0xbd, 0x37, 0xda, 0xde, 0x3d, 0x0f, 0x2f, 0x9b, 0xc7, 0x1f, 0xf1,
	0xfd, 0x7f, 0x78, 0x87, 0xef, 0x70, 0xe8, 0x6b, 0x65, 0xf5, 0x84, 0x69, 0xc8, 0x0c, 0x93, 0xe5,
	0xd5, 0xba, 0xc3, 0x9b, 0xd7, 0xf5, 0xdf, 0x23, 0x27, 0x4d, 0x9d, 0x32, 0xdd, 0xb6, 0x7f, 0x21,
	0xf1, 0x01, 0x8e, 0xae, 0x63, 0x87, 0x0f, 0x70, 0x77, 0x99, 0x2e, 0x59, 0x05, 0xcb, 0x1f, 0x87,
	0x3d, 0xf4, 0x9a, 0x55, 0x10, 0x6e, 0xe3, 0xce, 0x88, 0x57, 0xd1, 0x46, 0xbf, 0x33, 0xd8, 0x4c,
	0xdd, 0x73, 0xb7, 0x98, 0xcd, 0x49, 0x70, 0x31, 0x27, 0xc1, 0xe5, 0x9c, 0xa0, 0x4f, 0x0d, 0x41,
	0xdf, 0x1a, 0x82, 0xbe, 0x37, 0x04, 0xcd, 0x1a, 0x82, 0x7e, 0x34, 0x04, 0xfd, 0x6c, 0x48, 0x70,
	0xd9, 0x10, 0xf4, 0x65, 0x41, 0x82, 0xd9, 0x82, 0x04, 0x17, 0x0b, 0x12, 0xbc, 0x7d, 0x52, 0xf2,
	0x4a, 0x80, 0x15, 0x2c, 0xaf, 0x29, 0xe3, 0x89, 0x9f, 0x92, 0xb5, 0x9b, 0x7f, 0xe1, 0x5f, 0xf9,
	0x7f, 0xed, 0xc1, 0x3e, 0xfd, 0x15, 0x00, 0x00, 0xff, 0xff, 0xe1, 0x3a, 0x26, 0x54, 0x16, 0x03,
	0x00, 0x00,
}

func (this *ExecutionSpec) Equal(that interface{}) bool {
	if that == nil {
		return this == nil
	}

	that1, ok := that.(*ExecutionSpec)
	if !ok {
		that2, ok := that.(ExecutionSpec)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		return this == nil
	} else if this == nil {
		return false
	}
	if !this.Graph.Equal(that1.Graph) {
		return false
	}
	return true
}
func (this *ModelSpec) Equal(that interface{}) bool {
	if that == nil {
		return this == nil
	}

	that1, ok := that.(*ModelSpec)
	if !ok {
		that2, ok := that.(ModelSpec)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		return this == nil
	} else if this == nil {
		return false
	}
	if this.OnnxBlobKey != that1.OnnxBlobKey {
		return false
	}
	if !this.TensorrtSpec.Equal(that1.TensorrtSpec) {
		return false
	}
	return true
}
func (this *TensorRTModelSpec) Equal(that interface{}) bool {
	if that == nil {
		return this == nil
	}

	that1, ok := that.(*TensorRTModelSpec)
	if !ok {
		that2, ok := that.(TensorRTModelSpec)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		return this == nil
	} else if this == nil {
		return false
	}
	if len(this.OptimizationProfile) != len(that1.OptimizationProfile) {
		return false
	}
	for i := range this.OptimizationProfile {
		if !this.OptimizationProfile[i].Equal(that1.OptimizationProfile[i]) {
			return false
		}
	}
	if this.EngineBlobKey != that1.EngineBlobKey {
		return false
	}
	return true
}
func (this *TensorRTOptimizationProfile) Equal(that interface{}) bool {
	if that == nil {
		return this == nil
	}

	that1, ok := that.(*TensorRTOptimizationProfile)
	if !ok {
		that2, ok := that.(TensorRTOptimizationProfile)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		return this == nil
	} else if this == nil {
		return false
	}
	if len(this.TensorShapeRange) != len(that1.TensorShapeRange) {
		return false
	}
	for i := range this.TensorShapeRange {
		if !this.TensorShapeRange[i].Equal(that1.TensorShapeRange[i]) {
			return false
		}
	}
	return true
}
func (this *TensorRTTensorShapeRange) Equal(that interface{}) bool {
	if that == nil {
		return this == nil
	}

	that1, ok := that.(*TensorRTTensorShapeRange)
	if !ok {
		that2, ok := that.(TensorRTTensorShapeRange)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		return this == nil
	} else if this == nil {
		return false
	}
	if this.TensorName != that1.TensorName {
		return false
	}
	if len(this.Dim) != len(that1.Dim) {
		return false
	}
	for i := range this.Dim {
		if this.Dim[i] != that1.Dim[i] {
			return false
		}
	}
	return true
}
func (this *ExecutionSpec) GoString() string {
	if this == nil {
		return "nil"
	}
	s := make([]string, 0, 5)
	s = append(s, "&corepb.ExecutionSpec{")
	if this.Graph != nil {
		s = append(s, "Graph: "+fmt.Sprintf("%#v", this.Graph)+",\n")
	}
	s = append(s, "}")
	return strings.Join(s, "")
}
func (this *ModelSpec) GoString() string {
	if this == nil {
		return "nil"
	}
	s := make([]string, 0, 6)
	s = append(s, "&corepb.ModelSpec{")
	s = append(s, "OnnxBlobKey: "+fmt.Sprintf("%#v", this.OnnxBlobKey)+",\n")
	if this.TensorrtSpec != nil {
		s = append(s, "TensorrtSpec: "+fmt.Sprintf("%#v", this.TensorrtSpec)+",\n")
	}
	s = append(s, "}")
	return strings.Join(s, "")
}
func (this *TensorRTModelSpec) GoString() string {
	if this == nil {
		return "nil"
	}
	s := make([]string, 0, 6)
	s = append(s, "&corepb.TensorRTModelSpec{")
	if this.OptimizationProfile != nil {
		s = append(s, "OptimizationProfile: "+fmt.Sprintf("%#v", this.OptimizationProfile)+",\n")
	}
	s = append(s, "EngineBlobKey: "+fmt.Sprintf("%#v", this.EngineBlobKey)+",\n")
	s = append(s, "}")
	return strings.Join(s, "")
}
func (this *TensorRTOptimizationProfile) GoString() string {
	if this == nil {
		return "nil"
	}
	s := make([]string, 0, 5)
	s = append(s, "&corepb.TensorRTOptimizationProfile{")
	if this.TensorShapeRange != nil {
		s = append(s, "TensorShapeRange: "+fmt.Sprintf("%#v", this.TensorShapeRange)+",\n")
	}
	s = append(s, "}")
	return strings.Join(s, "")
}
func (this *TensorRTTensorShapeRange) GoString() string {
	if this == nil {
		return "nil"
	}
	s := make([]string, 0, 6)
	s = append(s, "&corepb.TensorRTTensorShapeRange{")
	s = append(s, "TensorName: "+fmt.Sprintf("%#v", this.TensorName)+",\n")
	s = append(s, "Dim: "+fmt.Sprintf("%#v", this.Dim)+",\n")
	s = append(s, "}")
	return strings.Join(s, "")
}
func valueToGoStringModelExec(v interface{}, typ string) string {
	rv := reflect.ValueOf(v)
	if rv.IsNil() {
		return "nil"
	}
	pv := reflect.Indirect(rv).Interface()
	return fmt.Sprintf("func(v %v) *%v { return &v } ( %#v )", typ, typ, pv)
}
func (m *ExecutionSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ExecutionSpec) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *ExecutionSpec) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.Graph != nil {
		{
			size, err := m.Graph.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintModelExec(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *ModelSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ModelSpec) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *ModelSpec) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.TensorrtSpec != nil {
		{
			size, err := m.TensorrtSpec.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintModelExec(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x6
		i--
		dAtA[i] = 0xa2
	}
	if len(m.OnnxBlobKey) > 0 {
		i -= len(m.OnnxBlobKey)
		copy(dAtA[i:], m.OnnxBlobKey)
		i = encodeVarintModelExec(dAtA, i, uint64(len(m.OnnxBlobKey)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *TensorRTModelSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *TensorRTModelSpec) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *TensorRTModelSpec) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.EngineBlobKey) > 0 {
		i -= len(m.EngineBlobKey)
		copy(dAtA[i:], m.EngineBlobKey)
		i = encodeVarintModelExec(dAtA, i, uint64(len(m.EngineBlobKey)))
		i--
		dAtA[i] = 0x12
	}
	if len(m.OptimizationProfile) > 0 {
		for iNdEx := len(m.OptimizationProfile) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.OptimizationProfile[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintModelExec(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0xa
		}
	}
	return len(dAtA) - i, nil
}

func (m *TensorRTOptimizationProfile) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *TensorRTOptimizationProfile) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *TensorRTOptimizationProfile) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.TensorShapeRange) > 0 {
		for iNdEx := len(m.TensorShapeRange) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.TensorShapeRange[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintModelExec(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0xa
		}
	}
	return len(dAtA) - i, nil
}

func (m *TensorRTTensorShapeRange) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *TensorRTTensorShapeRange) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *TensorRTTensorShapeRange) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.Dim) > 0 {
		dAtA4 := make([]byte, len(m.Dim)*10)
		var j3 int
		for _, num1 := range m.Dim {
			num := uint64(num1)
			for num >= 1<<7 {
				dAtA4[j3] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j3++
			}
			dAtA4[j3] = uint8(num)
			j3++
		}
		i -= j3
		copy(dAtA[i:], dAtA4[:j3])
		i = encodeVarintModelExec(dAtA, i, uint64(j3))
		i--
		dAtA[i] = 0x12
	}
	if len(m.TensorName) > 0 {
		i -= len(m.TensorName)
		copy(dAtA[i:], m.TensorName)
		i = encodeVarintModelExec(dAtA, i, uint64(len(m.TensorName)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func encodeVarintModelExec(dAtA []byte, offset int, v uint64) int {
	offset -= sovModelExec(v)
	base := offset
	for v >= 1<<7 {
		dAtA[offset] = uint8(v&0x7f | 0x80)
		v >>= 7
		offset++
	}
	dAtA[offset] = uint8(v)
	return base
}
func (m *ExecutionSpec) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Graph != nil {
		l = m.Graph.Size()
		n += 1 + l + sovModelExec(uint64(l))
	}
	return n
}

func (m *ModelSpec) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.OnnxBlobKey)
	if l > 0 {
		n += 1 + l + sovModelExec(uint64(l))
	}
	if m.TensorrtSpec != nil {
		l = m.TensorrtSpec.Size()
		n += 2 + l + sovModelExec(uint64(l))
	}
	return n
}

func (m *TensorRTModelSpec) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.OptimizationProfile) > 0 {
		for _, e := range m.OptimizationProfile {
			l = e.Size()
			n += 1 + l + sovModelExec(uint64(l))
		}
	}
	l = len(m.EngineBlobKey)
	if l > 0 {
		n += 1 + l + sovModelExec(uint64(l))
	}
	return n
}

func (m *TensorRTOptimizationProfile) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.TensorShapeRange) > 0 {
		for _, e := range m.TensorShapeRange {
			l = e.Size()
			n += 1 + l + sovModelExec(uint64(l))
		}
	}
	return n
}

func (m *TensorRTTensorShapeRange) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.TensorName)
	if l > 0 {
		n += 1 + l + sovModelExec(uint64(l))
	}
	if len(m.Dim) > 0 {
		l = 0
		for _, e := range m.Dim {
			l += sovModelExec(uint64(e))
		}
		n += 1 + sovModelExec(uint64(l)) + l
	}
	return n
}

func sovModelExec(x uint64) (n int) {
	return (math_bits.Len64(x|1) + 6) / 7
}
func sozModelExec(x uint64) (n int) {
	return sovModelExec(uint64((x << 1) ^ uint64((int64(x) >> 63))))
}
func (this *ExecutionSpec) String() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&ExecutionSpec{`,
		`Graph:` + strings.Replace(fmt.Sprintf("%v", this.Graph), "CalculatorGraphConfig", "framework.CalculatorGraphConfig", 1) + `,`,
		`}`,
	}, "")
	return s
}
func (this *ModelSpec) String() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&ModelSpec{`,
		`OnnxBlobKey:` + fmt.Sprintf("%v", this.OnnxBlobKey) + `,`,
		`TensorrtSpec:` + strings.Replace(this.TensorrtSpec.String(), "TensorRTModelSpec", "TensorRTModelSpec", 1) + `,`,
		`}`,
	}, "")
	return s
}
func (this *TensorRTModelSpec) String() string {
	if this == nil {
		return "nil"
	}
	repeatedStringForOptimizationProfile := "[]*TensorRTOptimizationProfile{"
	for _, f := range this.OptimizationProfile {
		repeatedStringForOptimizationProfile += strings.Replace(f.String(), "TensorRTOptimizationProfile", "TensorRTOptimizationProfile", 1) + ","
	}
	repeatedStringForOptimizationProfile += "}"
	s := strings.Join([]string{`&TensorRTModelSpec{`,
		`OptimizationProfile:` + repeatedStringForOptimizationProfile + `,`,
		`EngineBlobKey:` + fmt.Sprintf("%v", this.EngineBlobKey) + `,`,
		`}`,
	}, "")
	return s
}
func (this *TensorRTOptimizationProfile) String() string {
	if this == nil {
		return "nil"
	}
	repeatedStringForTensorShapeRange := "[]*TensorRTTensorShapeRange{"
	for _, f := range this.TensorShapeRange {
		repeatedStringForTensorShapeRange += strings.Replace(f.String(), "TensorRTTensorShapeRange", "TensorRTTensorShapeRange", 1) + ","
	}
	repeatedStringForTensorShapeRange += "}"
	s := strings.Join([]string{`&TensorRTOptimizationProfile{`,
		`TensorShapeRange:` + repeatedStringForTensorShapeRange + `,`,
		`}`,
	}, "")
	return s
}
func (this *TensorRTTensorShapeRange) String() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&TensorRTTensorShapeRange{`,
		`TensorName:` + fmt.Sprintf("%v", this.TensorName) + `,`,
		`Dim:` + fmt.Sprintf("%v", this.Dim) + `,`,
		`}`,
	}, "")
	return s
}
func valueToStringModelExec(v interface{}) string {
	rv := reflect.ValueOf(v)
	if rv.IsNil() {
		return "nil"
	}
	pv := reflect.Indirect(rv).Interface()
	return fmt.Sprintf("*%v", pv)
}
func (m *ExecutionSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowModelExec
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ExecutionSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ExecutionSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Graph", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowModelExec
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthModelExec
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthModelExec
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Graph == nil {
				m.Graph = &framework.CalculatorGraphConfig{}
			}
			if err := m.Graph.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipModelExec(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthModelExec
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ModelSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowModelExec
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ModelSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ModelSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OnnxBlobKey", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowModelExec
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthModelExec
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthModelExec
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.OnnxBlobKey = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 100:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TensorrtSpec", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowModelExec
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthModelExec
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthModelExec
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.TensorrtSpec == nil {
				m.TensorrtSpec = &TensorRTModelSpec{}
			}
			if err := m.TensorrtSpec.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipModelExec(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthModelExec
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *TensorRTModelSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowModelExec
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: TensorRTModelSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: TensorRTModelSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OptimizationProfile", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowModelExec
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthModelExec
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthModelExec
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.OptimizationProfile = append(m.OptimizationProfile, &TensorRTOptimizationProfile{})
			if err := m.OptimizationProfile[len(m.OptimizationProfile)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field EngineBlobKey", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowModelExec
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthModelExec
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthModelExec
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.EngineBlobKey = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipModelExec(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthModelExec
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *TensorRTOptimizationProfile) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowModelExec
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: TensorRTOptimizationProfile: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: TensorRTOptimizationProfile: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TensorShapeRange", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowModelExec
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthModelExec
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthModelExec
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.TensorShapeRange = append(m.TensorShapeRange, &TensorRTTensorShapeRange{})
			if err := m.TensorShapeRange[len(m.TensorShapeRange)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipModelExec(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthModelExec
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *TensorRTTensorShapeRange) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowModelExec
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: TensorRTTensorShapeRange: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: TensorRTTensorShapeRange: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TensorName", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowModelExec
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthModelExec
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthModelExec
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.TensorName = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType == 0 {
				var v int32
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowModelExec
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= int32(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.Dim = append(m.Dim, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowModelExec
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthModelExec
				}
				postIndex := iNdEx + packedLen
				if postIndex < 0 {
					return ErrInvalidLengthModelExec
				}
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				var elementCount int
				var count int
				for _, integer := range dAtA[iNdEx:postIndex] {
					if integer < 128 {
						count++
					}
				}
				elementCount = count
				if elementCount != 0 && len(m.Dim) == 0 {
					m.Dim = make([]int32, 0, elementCount)
				}
				for iNdEx < postIndex {
					var v int32
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowModelExec
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= int32(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.Dim = append(m.Dim, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field Dim", wireType)
			}
		default:
			iNdEx = preIndex
			skippy, err := skipModelExec(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthModelExec
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func skipModelExec(dAtA []byte) (n int, err error) {
	l := len(dAtA)
	iNdEx := 0
	depth := 0
	for iNdEx < l {
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return 0, ErrIntOverflowModelExec
			}
			if iNdEx >= l {
				return 0, io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		wireType := int(wire & 0x7)
		switch wireType {
		case 0:
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowModelExec
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				iNdEx++
				if dAtA[iNdEx-1] < 0x80 {
					break
				}
			}
		case 1:
			iNdEx += 8
		case 2:
			var length int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowModelExec
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				length |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if length < 0 {
				return 0, ErrInvalidLengthModelExec
			}
			iNdEx += length
		case 3:
			depth++
		case 4:
			if depth == 0 {
				return 0, ErrUnexpectedEndOfGroupModelExec
			}
			depth--
		case 5:
			iNdEx += 4
		default:
			return 0, fmt.Errorf("proto: illegal wireType %d", wireType)
		}
		if iNdEx < 0 {
			return 0, ErrInvalidLengthModelExec
		}
		if depth == 0 {
			return iNdEx, nil
		}
	}
	return 0, io.ErrUnexpectedEOF
}

var (
	ErrInvalidLengthModelExec        = fmt.Errorf("proto: negative length found during unmarshaling")
	ErrIntOverflowModelExec          = fmt.Errorf("proto: integer overflow")
	ErrUnexpectedEndOfGroupModelExec = fmt.Errorf("proto: unexpected end of group")
)
