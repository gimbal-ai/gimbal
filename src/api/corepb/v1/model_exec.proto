/*
 * Copyright 2023- Gimlet Labs, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 * SPDX-License-Identifier: Apache-2.0
 */

syntax = "proto3";

package gml.internal.api.core.v1;

option go_package = "gimletlabs.ai/gimlet/src/api/corepb/v1;corepb";

import "gogoproto/gogo.proto";
import "mediapipe/framework/calculator.proto";
import "src/common/typespb/uuid.proto";
import "google/protobuf/timestamp.proto";
import "google/protobuf/wrappers.proto";

/****************************************************************************
 * Model definitions.
 *****************************************************************************/
message BoundingBoxInfo {
  enum BoundingBoxFormat {
    BOUNDING_BOX_FORMAT_UNKNOWN = 0;
    // Center coordinate, and width and height.
    BOUNDING_BOX_FORMAT_CXCYWH = 1;
    // Top left and bottom right coordinates, with y dimension first.
    BOUNDING_BOX_FORMAT_YXYX = 2;
    // Top left and bottom right coordinates, with x dimension first.
    BOUNDING_BOX_FORMAT_XYXY = 3;
  }
  // The format of bounding boxes output by the detection model.
  BoundingBoxFormat box_format = 1;
  // Whether the bounding boxes output by the detection model are normalized to [0,1] or not.
  bool box_normalized = 2;
}

message ImagePreprocessingStep {
  enum ImagePreprocessingKind {
    IMAGE_PREPROCESSING_KIND_UNKNOWN = 0;
    IMAGE_PREPROCESSING_KIND_CONVERT_TO_TENSOR = 1;
    IMAGE_PREPROCESSING_KIND_RESIZE = 2;
    IMAGE_PREPROCESSING_KIND_STANDARDIZE = 3;
  }
  ImagePreprocessingKind kind = 1;

  message ImageConversionParams {
    // Whether to scale the image to [0, 1] from [0, 255].
    bool scale = 1;
  }
  ImageConversionParams conversion_params = 2;

  message ImageResizeParams {
    enum ImageResizeKind {
      IMAGE_RESIZE_KIND_UNKNOWN = 0;
      IMAGE_RESIZE_KIND_STRETCH = 1;
      IMAGE_RESIZE_KIND_LETTERBOX = 2;
    }
    ImageResizeKind kind = 1;
  }
  ImageResizeParams resize_params = 3;

  message ImageStandardizeParams {
    // Per-channel means to use for standardization.
    repeated float means = 1;
    // Per-channel standard deviations to use for standardization.
    repeated float stddevs = 2;
  }
  ImageStandardizeParams standardize_params = 4;
}

message DimensionSemantics {
  enum DimensionSemanticsKind {
    DIMENSION_SEMANTICS_KIND_UNKNOWN = 0;
    DIMENSION_SEMANTICS_KIND_BATCH = 1;
    DIMENSION_SEMANTICS_KIND_IGNORE = 2;
    DIMENSION_SEMANTICS_KIND_IMAGE_CHANNEL = 3;
    DIMENSION_SEMANTICS_KIND_IMAGE_HEIGHT = 4;
    DIMENSION_SEMANTICS_KIND_IMAGE_WIDTH = 5;
    DIMENSION_SEMANTICS_KIND_DETECTION_CANDIDATES = 6;
    DIMENSION_SEMANTICS_KIND_DETECTION_OUTPUT = 7;
    DIMENSION_SEMANTICS_KIND_CLASS_SCORES = 8;
    DIMENSION_SEMANTICS_KIND_SEGMENTATION_MASK_CHANNEL = 9;
    DIMENSION_SEMANTICS_KIND_CLASS_LABELS = 10;
    DIMENSION_SEMANTICS_KIND_REGRESSION_VALUE = 11;
    DIMENSION_SEMANTICS_KIND_TOKENS = 12;
    DIMENSION_SEMANTICS_KIND_ATTENTION_MASK = 13;
    DIMENSION_SEMANTICS_KIND_VOCAB_LOGITS = 14;
  }
  DimensionSemanticsKind kind = 1;

  // Parameters for ImageChannelSemantics.
  message ImageChannelParams {
    enum ImageChannelFormat {
      IMAGE_CHANNEL_FORMAT_UNKNOWN = 0;
      IMAGE_CHANNEL_FORMAT_RGB = 1;
      IMAGE_CHANNEL_FORMAT_BGR = 2;
    }
    ImageChannelFormat format = 1;
  }
  ImageChannelParams image_channel_params = 2;

  // Parameters for DetectionCandidatesSemantics.
  message DetectionCandidatesParams {
    // Returns whether these N candidates are the result of an NMS step (is_nms_boxes = true) or are
    // all candidate boxes (is_nms_boxes = false).
    bool is_nms_boxes = 1;
  }
  DetectionCandidatesParams detection_candidates_params = 3;

  // Parameters for DetectionOutputSemantics.
  message DetectionOutputParams {
    message IndexRange {
      int32 start = 1;
      int32 size = 2;
    }
    // Range of indices within the dimension that represent the coordinates of the detected box.
    IndexRange box_coordinate_range = 1;
    // Format of the box coodinates.
    BoundingBoxInfo box_format = 2;
    // Index containing confidence score of box. If `scores_range` is also specified then each
    // classes score is multiplied by this value.
    int32 box_confidence_index = 3;
    // Optional index into dimension containing class indices. One of `class_index` and
    // `scores_range` must be specified.
    int32 class_index = 4;
    // Range of indices containing the scores per-class. The highest score is taken as the detected
    // class.
    IndexRange scores_range = 5;
  }
  DetectionOutputParams detection_output_params = 4;

  message SegmentationMaskParams {
    enum SegmentationMaskKind {
      SEGMENTATION_MASK_KIND_UNKNOWN = 0;
      // Segmenation masks represented by an integer tensor where each pixel is a class label.
      SEGMENTATION_MASK_KIND_CLASS_LABEL = 1;
      // Segmentation masks represented by a boolean tensor where each channel is a different class'
      // mask.
      SEGMENTATION_MASK_KIND_BOOL = 2;
      // Segmentation masks represented by a float tensor where each channel is a different class'
      // confidence score at each pixel.
      SEGMENTATION_MASK_KIND_SCORE = 3;
    }
    SegmentationMaskKind kind = 1;
  }
  SegmentationMaskParams segmentation_mask_params = 5;

  message RegressionParams {
    // Label to give to the regression value.
    string label = 1;
    // Optional scalar multiplier for regression output.
    google.protobuf.DoubleValue scale = 2;
  }
  RegressionParams regression_params = 6;
}

// Semantics of an input/output tensor. Used to determine pre/post-processing necessary for
// inputs/outputs of model.
message TensorSemantics {
  // Semantics for each dimension in the tensor.
  repeated DimensionSemantics dimensions = 1;
}

message ModelInfo {
  // Name of the model. Used to reference the model in pipelines.
  string name = 1;

  enum ModelKind {
    MODEL_KIND_UNKNOWN = 0;
    MODEL_KIND_TORCH = 1;
    MODEL_KIND_TORCHSCRIPT = 2;
    MODEL_KIND_ONNX = 3;
    MODEL_KIND_TFLITE = 4;
    MODEL_KIND_OPENVINO = 5;
    MODEL_KIND_HUGGINGFACE_TOKENIZER = 6;
  }
  ModelKind kind = 2;

  enum ModelStorageFormat {
    MODEL_STORAGE_FORMAT_UNKNOWN = 0;
    MODEL_STORAGE_FORMAT_MLIR_BYTECODE = 1;
    MODEL_STORAGE_FORMAT_MLIR_TEXT = 2;
    MODEL_STORAGE_FORMAT_PROTOBUF = 3;
    MODEL_STORAGE_FORMAT_PROTO_TEXT = 4;
    MODEL_STORAGE_FORMAT_FLATBUFFER = 5;
    MODEL_STORAGE_FORMAT_OPENVINO = 6;
    // Opaque models are ignored by MLIR processing.
    MODEL_STORAGE_FORMAT_OPAQUE = 7;
  }
  ModelStorageFormat format = 3;

  // Map from asset name to ID of the uploaded file. Interpretation of the names depends on the
  // storage format. For most formats, there will be a single asset with an empty string name.
  // Formats that require multiple files each have there own names for the assets. For example,
  // OpenVINO format will have a file called "weights" and a file called "model".
  map<string, gml.types.UUID> file_assets = 4;

  // Semantics of each input tensor. Describes the layout and semantic kind of each dimension in an
  // input tensor.
  repeated TensorSemantics input_tensor_semantics = 5;
  // Semantics of each output tensor. Describes the layout and semantic kind of each dimension in an
  // output tensor.
  repeated TensorSemantics output_tensor_semantics = 6;

  // All of the following fields are optional and their presence depends on the type of model.

  // For models that output classifications/detections, this is the list of class names output by
  // the model.
  repeated string class_labels = 100;

  // Information about the bounding boxes output by the model, specified only if the model outputs
  // bounding boxes.
  BoundingBoxInfo bbox_info = 101;

  // Stages of preprocessing necessary if the model accepts an image tensor as input.
  repeated ImagePreprocessingStep image_preprocessing_steps = 102;
}

/****************************************************************************
 * Logical Pipeline definitions.
 *****************************************************************************/

// All supported logical pipeline nodes.
enum LogicalPipelineNodeKind {
  LOGICAL_PIPELINE_NODE_KIND_UNKNOWN = 0;
  // Source nodes
  LOGICAL_PIPELINE_NODE_KIND_CAMERA_SOURCE = 10;
  LOGICAL_PIPELINE_NODE_KIND_TEXT_STREAM_SOURCE = 11;
  // Model nodes
  LOGICAL_PIPELINE_NODE_KIND_DETECT = 1000;
  LOGICAL_PIPELINE_NODE_KIND_CLASSIFY = 1001;
  LOGICAL_PIPELINE_NODE_KIND_SEGMENT = 1002;
  LOGICAL_PIPELINE_NODE_KIND_MULTI_PURPOSE_MODEL = 1003;
  LOGICAL_PIPELINE_NODE_KIND_REGRESS = 1004;
  LOGICAL_PIPELINE_NODE_KIND_TRACK = 1005;
  LOGICAL_PIPELINE_NODE_KIND_GENERATE_TOKENS = 1006;
  // Processing nodes
  LOGICAL_PIPELINE_NODE_KIND_FOR_EACH_ROI = 1503;
  // Sink nodes
  LOGICAL_PIPELINE_NODE_KIND_VIDEO_STREAM_SINK = 2000;
  LOGICAL_PIPELINE_NODE_KIND_DETECTIONS_METRICS_SINK = 2001;
  LOGICAL_PIPELINE_NODE_KIND_LATENCY_METRICS_SINK = 2002;
  LOGICAL_PIPELINE_NODE_KIND_FRAME_METRICS_SINK = 2003;
  LOGICAL_PIPELINE_NODE_KIND_TEXT_STREAM_SINK = 2004;
}

// A node in a logical pipeline graph.
message Node {
  // Unique name for the node in the logical pipeline.
  string name = 1;
  LogicalPipelineNodeKind kind = 2;
  repeated NodeAttributes attributes = 3;
  repeated NodeInput inputs = 4;
  repeated NodeOutput outputs = 5;
}

// A reference to a param.
message ParamRef {
  // Name of the param.
  string name = 1;
}

message Value {
  message ModelRef {
    // Name of the model.
    string name = 1;
    // ID of the model.
    types.UUID id = 2 [ (gogoproto.customname) = "ID" ];
  }

  message Lambda {
    repeated string inputs = 1;
    repeated string outputs = 2;
    repeated Node nodes = 3;
  }

  oneof data {
    string string_data = 1;
    int64 int64_data = 2;
    double double_data = 3;
    bool bool_data = 4;
    Lambda lambda_data = 5;
    ModelRef model_data = 6;
    ParamRef param_data = 7;
  }
}

// NodeAttributes are constants that are used by the node.
message NodeAttributes {
  // Name of the attribute.
  string name = 1;
  Value value = 2;
}

// Input values for a node.
message NodeInput {
  // A reference to an output field of another node in the logical pipeline.
  message NodeOutputRef {
    // Name of the node that produced this output.
    string node_name = 1;
    // Name of the node's output field.
    string name = 2;
  }

  // If this node is used in a Lambda node, this is the input from the Lambda caller.
  message LambdaInputRef {
    // Name of the lambda input.
    string name = 1;
  }

  // Name of the input.
  string name = 1;
  oneof value {
    // The name of a global param.
    ParamRef param_value = 2;
    // Input value is another node's output.
    NodeOutputRef node_output_value = 3;
    LambdaInputRef lambda_input_value = 4;
  }
}

// Output values for a node.
message NodeOutput {
  // Name of the output field. This must be unique within the logical pipeline, as other nodes may
  // reference it.
  string name = 1;
}

// Params that are used to configure the pipeline.
message Param {
  // Name of the param.
  string name = 1;
  Value default_value = 2;
}

// A logical pipeline represents the high level steps of an execution graph. Users specify their
// pipeline YAML which is converted into this proto format.
message LogicalPipeline {
  // Params that are used to configure the pipeline.
  repeated Param params = 1;
  // The nodes in the logical pipeline.
  repeated Node nodes = 2;
  // List of all models used by the pipeline.
  repeated gml.types.UUID model_ids = 3 [ (gogoproto.customname) = "ModelIDs" ];
}

/****************************************************************************
 * Pipeline deployment definitions.
 *****************************************************************************/

enum PipelineState {
  PIPELINE_STATE_UNKNOWN = 0;
  PIPELINE_STATE_PENDING = 1;
  PIPELINE_STATE_READY = 2;
  PIPELINE_STATE_RUNNING = 3;
  PIPELINE_STATE_TERMINATING = 4;
  PIPELINE_STATE_TERMINATED = 5;
  PIPELINE_STATE_FAILED = 6;
}

// A pipeline deployment represents the instance of a logical pipeline deployed to a fleet.
message PipelineDeployment {
  // The ID of the deployment.
  gml.types.UUID id = 1 [ (gogoproto.customname) = "ID" ];
  // The ID of the logical pipeline this deployment is for.
  gml.types.UUID logical_pipeline_id = 2 [ (gogoproto.customname) = "LogicalPipelineID" ];
  // The ID of the fleet this pipeline should be deployed to.
  gml.types.UUID fleet_id = 3 [ (gogoproto.customname) = "FleetID" ];
  // The time this deployment was created.
  google.protobuf.Timestamp created_at = 4;
  // The time this deployment was last updated.
  google.protobuf.Timestamp updated_at = 5;
  // The version of the deployment.
  int64 version = 6;
  PipelineDeploymentSpec spec = 7;
  PipelineDeploymentStatus status = 8;
  // The time this deployment was deleted.
  google.protobuf.Timestamp deleted_at = 9;
}

// The spec represents the desired state of the deployment.
message PipelineDeploymentSpec {
  // The state that we would like the deployment to be in.
  PipelineState state = 1;
}

// The state represents the actual state of the deployment.
message PipelineDeploymentStatus {
  // The state that the deployment is currently in.
  PipelineState state = 1;
  // The reason for why the deployment is in this state.
  string reason = 2;
}

// A physical pipeline represents the deployment of a pipeline to a specific device.
message PhysicalPipeline {
  // The ID of the physical pipeline.
  gml.types.UUID id = 1 [ (gogoproto.customname) = "ID" ];
  ;
  // The ID of the pipeline deployment this physical pipeline is for.
  gml.types.UUID pipeline_deployment_id = 2 [ (gogoproto.customname) = "PipelineDeploymentID" ];
  // The ID of the device this physical pipeline is for.
  gml.types.UUID device_id = 3 [ (gogoproto.customname) = "DeviceID" ];
  // The time this physical pipeline was created.
  google.protobuf.Timestamp created_at = 4;
  // The time this physical pipeline was last updated.
  google.protobuf.Timestamp updated_at = 5;
  // The spec of the deployment.
  PhysicalPipelineSpec spec = 6;
  // The state of the deployment.
  PhysicalPipelineStatus status = 7;
}

// The spec represents the desired state of the deployment.
message PhysicalPipelineSpec {
  // The state that we would like the pipeline to be in.
  PipelineState state = 1;
  // The version of the pipeline deployment that this spec is for.
  int64 version = 2;
  // The actual pipeline graph.
  gml.internal.api.core.v1.ExecutionSpec graph = 3;
  // The preferred runtime for the execution.
  string runtime = 4;
}

// The state represents the actual state of the deployment.
message PhysicalPipelineStatus {
  // The state that the pipeline is currently in.
  PipelineState state = 1;
  // The version of the pipeline deployment that this status is for.
  int64 version = 2;
  // The actual runtime for the device's execution.
  string runtime = 3;
  // The reason the pipeline is in this state.
  string reason = 4;
}

message FileResource {
  // The ID of the file to fetch.
  gml.types.UUID file_id = 1 [ (gogoproto.customname) = "FileID" ];
  // The size of the file, in bytes.
  uint64 size_bytes = 2;
  // The sha256hash of the file.
  string sha256_hash = 3;
}

// ExecutionSpec represents a deployment that the GEM should execute.
message ExecutionSpec {
  mediapipe.CalculatorGraphConfig graph = 1;

  // Any models referenced by any nodes in the graph above need to have a model spec.
  repeated ModelSpec model_spec = 2;
}

// NamedAsset represents a file asset for a model, tagged with a name that is interpreted by the
// model runtime.
message NamedAsset {
  string name = 1;
  FileResource file = 2;
}

// ModelSpec defines how to prepare the model.
// The current spec definitions are temporary and subject to change significantly.
message ModelSpec {
  string name = 1;

  // TODO(oazizi): Remove onnx_blob_key once file download work is complete; using name instead.
  string onnx_blob_key = 2 [ (gogoproto.customname) = "ONNXBlobKey" ];
  FileResource onnx_file = 3 [ (gogoproto.customname) = "ONNXFile" ];

  // Model file assets.
  // Asset naming is optional, and interpreted only by the runtime.
  repeated NamedAsset named_asset = 4;

  // The preferred runtime for the execution.
  string runtime = 50;

  // Plugin specs.
  // TensorRT specific specifications.
  TensorRTModelSpec tensorrt_spec = 100 [ (gogoproto.customname) = "TensorRTSpec" ];
  // OpenVINO specific specifications.
  OpenVINOModelSpec openvino_spec = 101 [ (gogoproto.customname) = "OpenVINOSpec" ];
}

// TensorRTModelSpec defines TensorRT specific parameters for building a TensorRT engine.
message TensorRTModelSpec {
  repeated TensorRTOptimizationProfile optimization_profile = 1;

  // BlobStore key for a cached version of the engine. If not empty, the model builder will attempt
  // to load the engine from the cached blob, if that fails it will build the engine and then insert
  // the built engine into the BlobStore with this key.
  string engine_blob_key = 2;

  TensorRTMemPoolLimits mem_pool_limits = 3;
}

// TensorRTOptimizationProfile defines TensorRT specific parameters to aid TensorRT profiling based
// optimization.
message TensorRTOptimizationProfile {
  repeated TensorRTTensorShapeRange tensor_shape_range = 1;
}

// TensorRTTensorShapeRange represents the range of shapes that a tensor is allowed to take.
// TensorRT uses this to aid in optimization.
message TensorRTTensorShapeRange {
  // For now we explicitly set the tensor shape instead of specifying a min/opt/max range.
  string tensor_name = 1;
  repeated int32 dim = 2;
}

message TensorRTMemPoolLimits {
  int64 workspace = 1;
}

message OpenVINOModelSpec {
  message TensorShape {
    repeated int32 dim = 1;
  }
  repeated TensorShape input_shape = 1;
}
