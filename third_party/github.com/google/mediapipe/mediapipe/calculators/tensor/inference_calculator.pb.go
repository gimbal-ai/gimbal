// Code generated by protoc-gen-gogo. DO NOT EDIT.
// source: mediapipe/calculators/tensor/inference_calculator.proto

package tensor

import (
	fmt "fmt"
	proto "github.com/gogo/protobuf/proto"
	framework "github.com/google/mediapipe/mediapipe/framework"
	io "io"
	math "math"
	math_bits "math/bits"
	reflect "reflect"
	strconv "strconv"
	strings "strings"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.GoGoProtoPackageIsVersion3 // please upgrade the proto package

type InferenceCalculatorOptions_Delegate_Gpu_Api int32

const (
	ANY    InferenceCalculatorOptions_Delegate_Gpu_Api = 0
	OPENGL InferenceCalculatorOptions_Delegate_Gpu_Api = 1
	OPENCL InferenceCalculatorOptions_Delegate_Gpu_Api = 2
)

var InferenceCalculatorOptions_Delegate_Gpu_Api_name = map[int32]string{
	0: "ANY",
	1: "OPENGL",
	2: "OPENCL",
}

var InferenceCalculatorOptions_Delegate_Gpu_Api_value = map[string]int32{
	"ANY":    0,
	"OPENGL": 1,
	"OPENCL": 2,
}

func (x InferenceCalculatorOptions_Delegate_Gpu_Api) Enum() *InferenceCalculatorOptions_Delegate_Gpu_Api {
	p := new(InferenceCalculatorOptions_Delegate_Gpu_Api)
	*p = x
	return p
}

func (x InferenceCalculatorOptions_Delegate_Gpu_Api) MarshalJSON() ([]byte, error) {
	return proto.MarshalJSONEnum(InferenceCalculatorOptions_Delegate_Gpu_Api_name, int32(x))
}

func (x *InferenceCalculatorOptions_Delegate_Gpu_Api) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(InferenceCalculatorOptions_Delegate_Gpu_Api_value, data, "InferenceCalculatorOptions_Delegate_Gpu_Api")
	if err != nil {
		return err
	}
	*x = InferenceCalculatorOptions_Delegate_Gpu_Api(value)
	return nil
}

func (InferenceCalculatorOptions_Delegate_Gpu_Api) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_56577d0329bf61c8, []int{0, 0, 1, 0}
}

type InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior int32

const (
	NO_WRITE       InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior = 0
	TRY_WRITE      InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior = 1
	WRITE_OR_ERROR InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior = 2
)

var InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior_name = map[int32]string{
	0: "NO_WRITE",
	1: "TRY_WRITE",
	2: "WRITE_OR_ERROR",
}

var InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior_value = map[string]int32{
	"NO_WRITE":       0,
	"TRY_WRITE":      1,
	"WRITE_OR_ERROR": 2,
}

func (x InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior) Enum() *InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior {
	p := new(InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior)
	*p = x
	return p
}

func (x InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior) MarshalJSON() ([]byte, error) {
	return proto.MarshalJSONEnum(InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior_name, int32(x))
}

func (x *InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior_value, data, "InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior")
	if err != nil {
		return err
	}
	*x = InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior(value)
	return nil
}

func (InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_56577d0329bf61c8, []int{0, 0, 1, 1}
}

type InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage int32

const (
	UNSPECIFIED        InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage = 0
	FAST_SINGLE_ANSWER InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage = 1
	SUSTAINED_SPEED    InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage = 2
)

var InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage_name = map[int32]string{
	0: "UNSPECIFIED",
	1: "FAST_SINGLE_ANSWER",
	2: "SUSTAINED_SPEED",
}

var InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage_value = map[string]int32{
	"UNSPECIFIED":        0,
	"FAST_SINGLE_ANSWER": 1,
	"SUSTAINED_SPEED":    2,
}

func (x InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage) Enum() *InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage {
	p := new(InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage)
	*p = x
	return p
}

func (x InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage) MarshalJSON() ([]byte, error) {
	return proto.MarshalJSONEnum(InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage_name, int32(x))
}

func (x *InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage_value, data, "InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage")
	if err != nil {
		return err
	}
	*x = InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage(value)
	return nil
}

func (InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_56577d0329bf61c8, []int{0, 0, 1, 2}
}

type InferenceCalculatorOptions struct {
	ModelPath    string                               `protobuf:"bytes,1,opt,name=model_path,json=modelPath" json:"model_path"`
	UseGpu       *bool                                `protobuf:"varint,2,opt,name=use_gpu,json=useGpu,def=0" json:"use_gpu,omitempty"`       // Deprecated: Do not use.
	UseNnapi     *bool                                `protobuf:"varint,3,opt,name=use_nnapi,json=useNnapi,def=0" json:"use_nnapi,omitempty"` // Deprecated: Do not use.
	CpuNumThread *int32                               `protobuf:"varint,4,opt,name=cpu_num_thread,json=cpuNumThread,def=-1" json:"cpu_num_thread,omitempty"`
	Delegate     *InferenceCalculatorOptions_Delegate `protobuf:"bytes,5,opt,name=delegate" json:"delegate,omitempty"`
}

func (m *InferenceCalculatorOptions) Reset()      { *m = InferenceCalculatorOptions{} }
func (*InferenceCalculatorOptions) ProtoMessage() {}
func (*InferenceCalculatorOptions) Descriptor() ([]byte, []int) {
	return fileDescriptor_56577d0329bf61c8, []int{0}
}
func (m *InferenceCalculatorOptions) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *InferenceCalculatorOptions) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_InferenceCalculatorOptions.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *InferenceCalculatorOptions) XXX_Merge(src proto.Message) {
	xxx_messageInfo_InferenceCalculatorOptions.Merge(m, src)
}
func (m *InferenceCalculatorOptions) XXX_Size() int {
	return m.Size()
}
func (m *InferenceCalculatorOptions) XXX_DiscardUnknown() {
	xxx_messageInfo_InferenceCalculatorOptions.DiscardUnknown(m)
}

var xxx_messageInfo_InferenceCalculatorOptions proto.InternalMessageInfo

const Default_InferenceCalculatorOptions_UseGpu bool = false
const Default_InferenceCalculatorOptions_UseNnapi bool = false
const Default_InferenceCalculatorOptions_CpuNumThread int32 = -1

func (m *InferenceCalculatorOptions) GetModelPath() string {
	if m != nil {
		return m.ModelPath
	}
	return ""
}

// Deprecated: Do not use.
func (m *InferenceCalculatorOptions) GetUseGpu() bool {
	if m != nil && m.UseGpu != nil {
		return *m.UseGpu
	}
	return Default_InferenceCalculatorOptions_UseGpu
}

// Deprecated: Do not use.
func (m *InferenceCalculatorOptions) GetUseNnapi() bool {
	if m != nil && m.UseNnapi != nil {
		return *m.UseNnapi
	}
	return Default_InferenceCalculatorOptions_UseNnapi
}

func (m *InferenceCalculatorOptions) GetCpuNumThread() int32 {
	if m != nil && m.CpuNumThread != nil {
		return *m.CpuNumThread
	}
	return Default_InferenceCalculatorOptions_CpuNumThread
}

func (m *InferenceCalculatorOptions) GetDelegate() *InferenceCalculatorOptions_Delegate {
	if m != nil {
		return m.Delegate
	}
	return nil
}

var E_InferenceCalculatorOptions_Ext = &proto.ExtensionDesc{
	ExtendedType:  (*framework.CalculatorOptions)(nil),
	ExtensionType: (*InferenceCalculatorOptions)(nil),
	Field:         336783863,
	Name:          "mediapipe.InferenceCalculatorOptions.ext",
	Tag:           "bytes,336783863,opt,name=ext",
	Filename:      "mediapipe/calculators/tensor/inference_calculator.proto",
}

type InferenceCalculatorOptions_Delegate struct {
	// Types that are valid to be assigned to Delegate:
	//	*InferenceCalculatorOptions_Delegate_Tflite
	//	*InferenceCalculatorOptions_Delegate_Gpu_
	//	*InferenceCalculatorOptions_Delegate_Nnapi_
	//	*InferenceCalculatorOptions_Delegate_Xnnpack_
	Delegate isInferenceCalculatorOptions_Delegate_Delegate `protobuf_oneof:"delegate"`
}

func (m *InferenceCalculatorOptions_Delegate) Reset()      { *m = InferenceCalculatorOptions_Delegate{} }
func (*InferenceCalculatorOptions_Delegate) ProtoMessage() {}
func (*InferenceCalculatorOptions_Delegate) Descriptor() ([]byte, []int) {
	return fileDescriptor_56577d0329bf61c8, []int{0, 0}
}
func (m *InferenceCalculatorOptions_Delegate) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *InferenceCalculatorOptions_Delegate) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_InferenceCalculatorOptions_Delegate.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *InferenceCalculatorOptions_Delegate) XXX_Merge(src proto.Message) {
	xxx_messageInfo_InferenceCalculatorOptions_Delegate.Merge(m, src)
}
func (m *InferenceCalculatorOptions_Delegate) XXX_Size() int {
	return m.Size()
}
func (m *InferenceCalculatorOptions_Delegate) XXX_DiscardUnknown() {
	xxx_messageInfo_InferenceCalculatorOptions_Delegate.DiscardUnknown(m)
}

var xxx_messageInfo_InferenceCalculatorOptions_Delegate proto.InternalMessageInfo

type isInferenceCalculatorOptions_Delegate_Delegate interface {
	isInferenceCalculatorOptions_Delegate_Delegate()
	Equal(interface{}) bool
	MarshalTo([]byte) (int, error)
	Size() int
}

type InferenceCalculatorOptions_Delegate_Tflite struct {
	Tflite *InferenceCalculatorOptions_Delegate_TfLite `protobuf:"bytes,1,opt,name=tflite,oneof" json:"tflite,omitempty"`
}
type InferenceCalculatorOptions_Delegate_Gpu_ struct {
	Gpu *InferenceCalculatorOptions_Delegate_Gpu `protobuf:"bytes,2,opt,name=gpu,oneof" json:"gpu,omitempty"`
}
type InferenceCalculatorOptions_Delegate_Nnapi_ struct {
	Nnapi *InferenceCalculatorOptions_Delegate_Nnapi `protobuf:"bytes,3,opt,name=nnapi,oneof" json:"nnapi,omitempty"`
}
type InferenceCalculatorOptions_Delegate_Xnnpack_ struct {
	Xnnpack *InferenceCalculatorOptions_Delegate_Xnnpack `protobuf:"bytes,4,opt,name=xnnpack,oneof" json:"xnnpack,omitempty"`
}

func (*InferenceCalculatorOptions_Delegate_Tflite) isInferenceCalculatorOptions_Delegate_Delegate() {}
func (*InferenceCalculatorOptions_Delegate_Gpu_) isInferenceCalculatorOptions_Delegate_Delegate()   {}
func (*InferenceCalculatorOptions_Delegate_Nnapi_) isInferenceCalculatorOptions_Delegate_Delegate() {}
func (*InferenceCalculatorOptions_Delegate_Xnnpack_) isInferenceCalculatorOptions_Delegate_Delegate() {
}

func (m *InferenceCalculatorOptions_Delegate) GetDelegate() isInferenceCalculatorOptions_Delegate_Delegate {
	if m != nil {
		return m.Delegate
	}
	return nil
}

func (m *InferenceCalculatorOptions_Delegate) GetTflite() *InferenceCalculatorOptions_Delegate_TfLite {
	if x, ok := m.GetDelegate().(*InferenceCalculatorOptions_Delegate_Tflite); ok {
		return x.Tflite
	}
	return nil
}

func (m *InferenceCalculatorOptions_Delegate) GetGpu() *InferenceCalculatorOptions_Delegate_Gpu {
	if x, ok := m.GetDelegate().(*InferenceCalculatorOptions_Delegate_Gpu_); ok {
		return x.Gpu
	}
	return nil
}

func (m *InferenceCalculatorOptions_Delegate) GetNnapi() *InferenceCalculatorOptions_Delegate_Nnapi {
	if x, ok := m.GetDelegate().(*InferenceCalculatorOptions_Delegate_Nnapi_); ok {
		return x.Nnapi
	}
	return nil
}

func (m *InferenceCalculatorOptions_Delegate) GetXnnpack() *InferenceCalculatorOptions_Delegate_Xnnpack {
	if x, ok := m.GetDelegate().(*InferenceCalculatorOptions_Delegate_Xnnpack_); ok {
		return x.Xnnpack
	}
	return nil
}

// XXX_OneofWrappers is for the internal use of the proto package.
func (*InferenceCalculatorOptions_Delegate) XXX_OneofWrappers() []interface{} {
	return []interface{}{
		(*InferenceCalculatorOptions_Delegate_Tflite)(nil),
		(*InferenceCalculatorOptions_Delegate_Gpu_)(nil),
		(*InferenceCalculatorOptions_Delegate_Nnapi_)(nil),
		(*InferenceCalculatorOptions_Delegate_Xnnpack_)(nil),
	}
}

type InferenceCalculatorOptions_Delegate_TfLite struct {
}

func (m *InferenceCalculatorOptions_Delegate_TfLite) Reset() {
	*m = InferenceCalculatorOptions_Delegate_TfLite{}
}
func (*InferenceCalculatorOptions_Delegate_TfLite) ProtoMessage() {}
func (*InferenceCalculatorOptions_Delegate_TfLite) Descriptor() ([]byte, []int) {
	return fileDescriptor_56577d0329bf61c8, []int{0, 0, 0}
}
func (m *InferenceCalculatorOptions_Delegate_TfLite) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *InferenceCalculatorOptions_Delegate_TfLite) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_InferenceCalculatorOptions_Delegate_TfLite.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *InferenceCalculatorOptions_Delegate_TfLite) XXX_Merge(src proto.Message) {
	xxx_messageInfo_InferenceCalculatorOptions_Delegate_TfLite.Merge(m, src)
}
func (m *InferenceCalculatorOptions_Delegate_TfLite) XXX_Size() int {
	return m.Size()
}
func (m *InferenceCalculatorOptions_Delegate_TfLite) XXX_DiscardUnknown() {
	xxx_messageInfo_InferenceCalculatorOptions_Delegate_TfLite.DiscardUnknown(m)
}

var xxx_messageInfo_InferenceCalculatorOptions_Delegate_TfLite proto.InternalMessageInfo

type InferenceCalculatorOptions_Delegate_Gpu struct {
	UseAdvancedGpuApi    *bool                                                         `protobuf:"varint,1,opt,name=use_advanced_gpu_api,json=useAdvancedGpuApi,def=0" json:"use_advanced_gpu_api,omitempty"`
	Api                  *InferenceCalculatorOptions_Delegate_Gpu_Api                  `protobuf:"varint,4,opt,name=api,enum=mediapipe.InferenceCalculatorOptions_Delegate_Gpu_Api,def=0" json:"api,omitempty"`
	AllowPrecisionLoss   *bool                                                         `protobuf:"varint,3,opt,name=allow_precision_loss,json=allowPrecisionLoss,def=1" json:"allow_precision_loss,omitempty"`
	CachedKernelPath     string                                                        `protobuf:"bytes,2,opt,name=cached_kernel_path,json=cachedKernelPath" json:"cached_kernel_path"`
	SerializedModelDir   string                                                        `protobuf:"bytes,7,opt,name=serialized_model_dir,json=serializedModelDir" json:"serialized_model_dir"`
	CacheWritingBehavior *InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior `protobuf:"varint,10,opt,name=cache_writing_behavior,json=cacheWritingBehavior,enum=mediapipe.InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior,def=2" json:"cache_writing_behavior,omitempty"`
	ModelToken           string                                                        `protobuf:"bytes,8,opt,name=model_token,json=modelToken" json:"model_token"`
	Usage                *InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage       `protobuf:"varint,5,opt,name=usage,enum=mediapipe.InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage,def=2" json:"usage,omitempty"`
}

func (m *InferenceCalculatorOptions_Delegate_Gpu) Reset() {
	*m = InferenceCalculatorOptions_Delegate_Gpu{}
}
func (*InferenceCalculatorOptions_Delegate_Gpu) ProtoMessage() {}
func (*InferenceCalculatorOptions_Delegate_Gpu) Descriptor() ([]byte, []int) {
	return fileDescriptor_56577d0329bf61c8, []int{0, 0, 1}
}
func (m *InferenceCalculatorOptions_Delegate_Gpu) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *InferenceCalculatorOptions_Delegate_Gpu) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_InferenceCalculatorOptions_Delegate_Gpu.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *InferenceCalculatorOptions_Delegate_Gpu) XXX_Merge(src proto.Message) {
	xxx_messageInfo_InferenceCalculatorOptions_Delegate_Gpu.Merge(m, src)
}
func (m *InferenceCalculatorOptions_Delegate_Gpu) XXX_Size() int {
	return m.Size()
}
func (m *InferenceCalculatorOptions_Delegate_Gpu) XXX_DiscardUnknown() {
	xxx_messageInfo_InferenceCalculatorOptions_Delegate_Gpu.DiscardUnknown(m)
}

var xxx_messageInfo_InferenceCalculatorOptions_Delegate_Gpu proto.InternalMessageInfo

const Default_InferenceCalculatorOptions_Delegate_Gpu_UseAdvancedGpuApi bool = false
const Default_InferenceCalculatorOptions_Delegate_Gpu_Api InferenceCalculatorOptions_Delegate_Gpu_Api = ANY
const Default_InferenceCalculatorOptions_Delegate_Gpu_AllowPrecisionLoss bool = true
const Default_InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior = WRITE_OR_ERROR
const Default_InferenceCalculatorOptions_Delegate_Gpu_Usage InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage = SUSTAINED_SPEED

func (m *InferenceCalculatorOptions_Delegate_Gpu) GetUseAdvancedGpuApi() bool {
	if m != nil && m.UseAdvancedGpuApi != nil {
		return *m.UseAdvancedGpuApi
	}
	return Default_InferenceCalculatorOptions_Delegate_Gpu_UseAdvancedGpuApi
}

func (m *InferenceCalculatorOptions_Delegate_Gpu) GetApi() InferenceCalculatorOptions_Delegate_Gpu_Api {
	if m != nil && m.Api != nil {
		return *m.Api
	}
	return Default_InferenceCalculatorOptions_Delegate_Gpu_Api
}

func (m *InferenceCalculatorOptions_Delegate_Gpu) GetAllowPrecisionLoss() bool {
	if m != nil && m.AllowPrecisionLoss != nil {
		return *m.AllowPrecisionLoss
	}
	return Default_InferenceCalculatorOptions_Delegate_Gpu_AllowPrecisionLoss
}

func (m *InferenceCalculatorOptions_Delegate_Gpu) GetCachedKernelPath() string {
	if m != nil {
		return m.CachedKernelPath
	}
	return ""
}

func (m *InferenceCalculatorOptions_Delegate_Gpu) GetSerializedModelDir() string {
	if m != nil {
		return m.SerializedModelDir
	}
	return ""
}

func (m *InferenceCalculatorOptions_Delegate_Gpu) GetCacheWritingBehavior() InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior {
	if m != nil && m.CacheWritingBehavior != nil {
		return *m.CacheWritingBehavior
	}
	return Default_InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior
}

func (m *InferenceCalculatorOptions_Delegate_Gpu) GetModelToken() string {
	if m != nil {
		return m.ModelToken
	}
	return ""
}

func (m *InferenceCalculatorOptions_Delegate_Gpu) GetUsage() InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage {
	if m != nil && m.Usage != nil {
		return *m.Usage
	}
	return Default_InferenceCalculatorOptions_Delegate_Gpu_Usage
}

type InferenceCalculatorOptions_Delegate_Nnapi struct {
	CacheDir        string `protobuf:"bytes,1,opt,name=cache_dir,json=cacheDir" json:"cache_dir"`
	ModelToken      string `protobuf:"bytes,2,opt,name=model_token,json=modelToken" json:"model_token"`
	AcceleratorName string `protobuf:"bytes,3,opt,name=accelerator_name,json=acceleratorName" json:"accelerator_name"`
}

func (m *InferenceCalculatorOptions_Delegate_Nnapi) Reset() {
	*m = InferenceCalculatorOptions_Delegate_Nnapi{}
}
func (*InferenceCalculatorOptions_Delegate_Nnapi) ProtoMessage() {}
func (*InferenceCalculatorOptions_Delegate_Nnapi) Descriptor() ([]byte, []int) {
	return fileDescriptor_56577d0329bf61c8, []int{0, 0, 2}
}
func (m *InferenceCalculatorOptions_Delegate_Nnapi) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *InferenceCalculatorOptions_Delegate_Nnapi) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_InferenceCalculatorOptions_Delegate_Nnapi.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *InferenceCalculatorOptions_Delegate_Nnapi) XXX_Merge(src proto.Message) {
	xxx_messageInfo_InferenceCalculatorOptions_Delegate_Nnapi.Merge(m, src)
}
func (m *InferenceCalculatorOptions_Delegate_Nnapi) XXX_Size() int {
	return m.Size()
}
func (m *InferenceCalculatorOptions_Delegate_Nnapi) XXX_DiscardUnknown() {
	xxx_messageInfo_InferenceCalculatorOptions_Delegate_Nnapi.DiscardUnknown(m)
}

var xxx_messageInfo_InferenceCalculatorOptions_Delegate_Nnapi proto.InternalMessageInfo

func (m *InferenceCalculatorOptions_Delegate_Nnapi) GetCacheDir() string {
	if m != nil {
		return m.CacheDir
	}
	return ""
}

func (m *InferenceCalculatorOptions_Delegate_Nnapi) GetModelToken() string {
	if m != nil {
		return m.ModelToken
	}
	return ""
}

func (m *InferenceCalculatorOptions_Delegate_Nnapi) GetAcceleratorName() string {
	if m != nil {
		return m.AcceleratorName
	}
	return ""
}

type InferenceCalculatorOptions_Delegate_Xnnpack struct {
	NumThreads *int32 `protobuf:"varint,1,opt,name=num_threads,json=numThreads,def=-1" json:"num_threads,omitempty"`
}

func (m *InferenceCalculatorOptions_Delegate_Xnnpack) Reset() {
	*m = InferenceCalculatorOptions_Delegate_Xnnpack{}
}
func (*InferenceCalculatorOptions_Delegate_Xnnpack) ProtoMessage() {}
func (*InferenceCalculatorOptions_Delegate_Xnnpack) Descriptor() ([]byte, []int) {
	return fileDescriptor_56577d0329bf61c8, []int{0, 0, 3}
}
func (m *InferenceCalculatorOptions_Delegate_Xnnpack) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *InferenceCalculatorOptions_Delegate_Xnnpack) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_InferenceCalculatorOptions_Delegate_Xnnpack.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *InferenceCalculatorOptions_Delegate_Xnnpack) XXX_Merge(src proto.Message) {
	xxx_messageInfo_InferenceCalculatorOptions_Delegate_Xnnpack.Merge(m, src)
}
func (m *InferenceCalculatorOptions_Delegate_Xnnpack) XXX_Size() int {
	return m.Size()
}
func (m *InferenceCalculatorOptions_Delegate_Xnnpack) XXX_DiscardUnknown() {
	xxx_messageInfo_InferenceCalculatorOptions_Delegate_Xnnpack.DiscardUnknown(m)
}

var xxx_messageInfo_InferenceCalculatorOptions_Delegate_Xnnpack proto.InternalMessageInfo

const Default_InferenceCalculatorOptions_Delegate_Xnnpack_NumThreads int32 = -1

func (m *InferenceCalculatorOptions_Delegate_Xnnpack) GetNumThreads() int32 {
	if m != nil && m.NumThreads != nil {
		return *m.NumThreads
	}
	return Default_InferenceCalculatorOptions_Delegate_Xnnpack_NumThreads
}

func init() {
	proto.RegisterEnum("mediapipe.InferenceCalculatorOptions_Delegate_Gpu_Api", InferenceCalculatorOptions_Delegate_Gpu_Api_name, InferenceCalculatorOptions_Delegate_Gpu_Api_value)
	proto.RegisterEnum("mediapipe.InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior", InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior_name, InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior_value)
	proto.RegisterEnum("mediapipe.InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage", InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage_name, InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage_value)
	proto.RegisterExtension(E_InferenceCalculatorOptions_Ext)
	proto.RegisterType((*InferenceCalculatorOptions)(nil), "mediapipe.InferenceCalculatorOptions")
	proto.RegisterType((*InferenceCalculatorOptions_Delegate)(nil), "mediapipe.InferenceCalculatorOptions.Delegate")
	proto.RegisterType((*InferenceCalculatorOptions_Delegate_TfLite)(nil), "mediapipe.InferenceCalculatorOptions.Delegate.TfLite")
	proto.RegisterType((*InferenceCalculatorOptions_Delegate_Gpu)(nil), "mediapipe.InferenceCalculatorOptions.Delegate.Gpu")
	proto.RegisterType((*InferenceCalculatorOptions_Delegate_Nnapi)(nil), "mediapipe.InferenceCalculatorOptions.Delegate.Nnapi")
	proto.RegisterType((*InferenceCalculatorOptions_Delegate_Xnnpack)(nil), "mediapipe.InferenceCalculatorOptions.Delegate.Xnnpack")
}

func init() {
	proto.RegisterFile("mediapipe/calculators/tensor/inference_calculator.proto", fileDescriptor_56577d0329bf61c8)
}

var fileDescriptor_56577d0329bf61c8 = []byte{
	// 950 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0x9c, 0x55, 0xcd, 0x6f, 0xe3, 0x44,
	0x14, 0xf7, 0x24, 0x4d, 0x9b, 0xbc, 0xec, 0xb6, 0x66, 0xa8, 0x56, 0x56, 0x84, 0x4c, 0xc9, 0xd2,
	0x55, 0x0e, 0xe0, 0x88, 0x08, 0x0a, 0xca, 0x2d, 0x69, 0xdc, 0x34, 0x90, 0x75, 0xa2, 0x49, 0xaa,
	0x52, 0x2e, 0xd6, 0xac, 0x33, 0x49, 0x46, 0x75, 0x6c, 0xcb, 0x1f, 0xdb, 0x15, 0x27, 0xc4, 0x81,
	0x1b, 0x12, 0xe2, 0x2f, 0xe0, 0x82, 0xc4, 0x8d, 0x7f, 0x63, 0x25, 0x2e, 0x95, 0xb8, 0xec, 0x09,
	0xd1, 0xf4, 0xc2, 0x71, 0x6f, 0x5c, 0xd1, 0xd8, 0xf9, 0x22, 0x74, 0x57, 0x64, 0x6f, 0xc9, 0x7b,
	0xbf, 0xf7, 0x9b, 0xf7, 0xf9, 0x33, 0x7c, 0x3a, 0x61, 0x03, 0x4e, 0x3d, 0xee, 0xb1, 0xb2, 0x45,
	0x6d, 0x2b, 0xb2, 0x69, 0xe8, 0xfa, 0x41, 0x39, 0x64, 0x4e, 0xe0, 0xfa, 0x65, 0xee, 0x0c, 0x99,
	0xcf, 0x1c, 0x8b, 0x99, 0x4b, 0xa7, 0xe6, 0xf9, 0x6e, 0xe8, 0xe2, 0xdc, 0x22, 0xb0, 0xf0, 0xfe,
	0x92, 0x63, 0xe8, 0xd3, 0x09, 0xbb, 0x72, 0xfd, 0xcb, 0xf2, 0x7a, 0x40, 0xe1, 0x83, 0xd7, 0xa3,
	0x4c, 0xd7, 0x0b, 0xb9, 0xeb, 0x04, 0x09, 0xba, 0xf8, 0xdd, 0x7d, 0x28, 0xb4, 0xe6, 0xaf, 0x1f,
	0x2f, 0x50, 0x9d, 0x04, 0x84, 0x1f, 0x02, 0x4c, 0xdc, 0x01, 0xb3, 0x4d, 0x8f, 0x86, 0x63, 0x05,
	0x1d, 0xa0, 0x52, 0xae, 0xbe, 0xf5, 0xfc, 0x8f, 0x77, 0x25, 0x92, 0x8b, 0xed, 0x5d, 0x1a, 0x8e,
	0x71, 0x11, 0x76, 0xa2, 0x80, 0x99, 0x23, 0x2f, 0x52, 0x52, 0x07, 0xa8, 0x94, 0xad, 0x66, 0x86,
	0xd4, 0x0e, 0x58, 0x3d, 0xa5, 0x20, 0xb2, 0x1d, 0x05, 0xac, 0xe9, 0x45, 0xf8, 0x11, 0xe4, 0x04,
	0xc6, 0x71, 0xa8, 0xc7, 0x95, 0xf4, 0x3a, 0x2a, 0x1b, 0x05, 0xcc, 0x10, 0x2e, 0x5c, 0x82, 0x5d,
	0xcb, 0x8b, 0x4c, 0x27, 0x9a, 0x98, 0xe1, 0xd8, 0x67, 0x74, 0xa0, 0x6c, 0x1d, 0xa0, 0x52, 0xa6,
	0x9a, 0xfa, 0xf0, 0x23, 0x72, 0xcf, 0xf2, 0x22, 0x23, 0x9a, 0xf4, 0x63, 0x3b, 0xfe, 0x1c, 0xb2,
	0x03, 0x66, 0xb3, 0x11, 0x0d, 0x99, 0x92, 0x39, 0x40, 0xa5, 0x7c, 0x45, 0xd3, 0x16, 0xa5, 0x6b,
	0xaf, 0xae, 0x49, 0x6b, 0xcc, 0xa2, 0xc8, 0x22, 0xbe, 0xf0, 0x33, 0x40, 0x76, 0x6e, 0xc6, 0x1d,
	0xd8, 0x0e, 0x87, 0x36, 0x0f, 0x59, 0x5c, 0x6f, 0xbe, 0xf2, 0xc9, 0x66, 0xb4, 0x5a, 0x7f, 0xd8,
	0xe6, 0x21, 0x3b, 0x95, 0xc8, 0x8c, 0x06, 0x9f, 0x40, 0x7a, 0xde, 0x9b, 0x7c, 0xa5, 0xb2, 0x21,
	0x5b, 0xd3, 0x8b, 0x4e, 0x25, 0x22, 0x08, 0x70, 0x1b, 0x32, 0xcb, 0xfe, 0xe5, 0x2b, 0x1f, 0x6f,
	0xc8, 0x14, 0x37, 0xf8, 0x54, 0x22, 0x09, 0x09, 0x26, 0xb0, 0xf3, 0xcc, 0x71, 0x3c, 0x6a, 0x5d,
	0xc6, 0x2d, 0xce, 0x57, 0x8e, 0x36, 0xe4, 0xfb, 0x32, 0x89, 0x3e, 0x95, 0xc8, 0x9c, 0xa8, 0x90,
	0x85, 0xed, 0xa4, 0xfa, 0xc2, 0x8f, 0xdb, 0x90, 0x16, 0x73, 0x3f, 0x82, 0x7d, 0x31, 0x77, 0x3a,
	0x78, 0x4a, 0x1d, 0x8b, 0x0d, 0xc4, 0x92, 0x98, 0xa2, 0x04, 0xb4, 0xb2, 0x02, 0xe4, 0xad, 0x28,
	0x60, 0xb5, 0x19, 0xa2, 0xe9, 0x45, 0x35, 0x8f, 0xe3, 0xc7, 0x90, 0x16, 0x30, 0x91, 0xd9, 0xee,
	0xc6, 0x99, 0x35, 0xbd, 0x48, 0xab, 0x79, 0xbc, 0x9a, 0xae, 0x19, 0x17, 0x44, 0xf0, 0x88, 0x34,
	0xa8, 0x6d, 0xbb, 0x57, 0xa6, 0xe7, 0x33, 0x8b, 0x07, 0xdc, 0x75, 0x4c, 0xdb, 0x0d, 0x82, 0xd9,
	0x26, 0x6e, 0x85, 0x7e, 0xc4, 0x08, 0x8e, 0x11, 0xdd, 0x39, 0xa0, 0xed, 0x06, 0x01, 0xae, 0x00,
	0xb6, 0xa8, 0x35, 0x66, 0x03, 0xf3, 0x92, 0xf9, 0xce, 0xfc, 0x0e, 0x52, 0x2b, 0x77, 0x20, 0x27,
	0xfe, 0x2f, 0x62, 0x77, 0x7c, 0x0e, 0x47, 0xb0, 0x1f, 0x30, 0x9f, 0x53, 0x9b, 0x7f, 0xcd, 0x06,
	0x66, 0x72, 0x3e, 0x03, 0xee, 0x2b, 0x3b, 0x2b, 0x51, 0x78, 0x89, 0x78, 0x2c, 0x00, 0x0d, 0xee,
	0xe3, 0xef, 0x11, 0x3c, 0x88, 0xc9, 0xcc, 0x2b, 0x9f, 0x87, 0xdc, 0x19, 0x99, 0x4f, 0xd8, 0x98,
	0x3e, 0xe5, 0xae, 0xaf, 0x40, 0xdc, 0x86, 0xe6, 0x1b, 0xb4, 0xe1, 0x58, 0x10, 0x9e, 0x27, 0x7c,
	0xf5, 0x19, 0x5d, 0x75, 0xf7, 0x9c, 0xb4, 0xfa, 0xba, 0xd9, 0x21, 0xa6, 0x4e, 0x48, 0x87, 0x90,
	0x7d, 0xeb, 0x0e, 0x14, 0x3e, 0x84, 0x7c, 0x92, 0x7c, 0xe8, 0x5e, 0x32, 0x47, 0xc9, 0xae, 0xa4,
	0x9f, 0x88, 0x42, 0x5f, 0xd8, 0xf1, 0x18, 0x32, 0x51, 0x40, 0x47, 0xc9, 0x11, 0xee, 0x56, 0x6a,
	0x6f, 0x90, 0xe4, 0x02, 0x77, 0x26, 0x88, 0xaa, 0x7b, 0xbd, 0xb3, 0x5e, 0xbf, 0xd6, 0x32, 0xf4,
	0x86, 0xd9, 0xeb, 0xea, 0x7a, 0x83, 0x24, 0x0f, 0x14, 0x1f, 0x41, 0x5a, 0xac, 0xc6, 0x0e, 0x88,
	0xb9, 0xca, 0x12, 0x06, 0xd8, 0xee, 0x74, 0x75, 0xa3, 0xd9, 0x96, 0xd1, 0xfc, 0xf7, 0x71, 0x5b,
	0x4e, 0x15, 0x9b, 0xb0, 0x7f, 0x57, 0xd9, 0xf8, 0x1e, 0x64, 0x8d, 0x8e, 0x19, 0xd7, 0x2e, 0x4b,
	0xf8, 0x3e, 0xe4, 0xfa, 0xe4, 0x62, 0xf6, 0x17, 0x61, 0x0c, 0x6b, 0x5d, 0x91, 0x53, 0x45, 0x03,
	0x76, 0xff, 0x9d, 0x1a, 0xde, 0x83, 0xfc, 0x99, 0xd1, 0xeb, 0xea, 0xc7, 0xad, 0x93, 0x96, 0xde,
	0x90, 0x25, 0xfc, 0x00, 0xf0, 0x49, 0xad, 0xd7, 0x37, 0x7b, 0x2d, 0xa3, 0xd9, 0xd6, 0xcd, 0x9a,
	0xd1, 0x3b, 0xd7, 0x89, 0x8c, 0xf0, 0xdb, 0xb0, 0x5e, 0x85, 0x9c, 0x2a, 0x7c, 0x8b, 0x20, 0x93,
	0xc8, 0xdc, 0x7b, 0x90, 0x4b, 0x46, 0x2d, 0x16, 0x63, 0x55, 0x56, 0xb3, 0xb1, 0x59, 0xac, 0xc3,
	0x5a, 0xfb, 0x53, 0xaf, 0x68, 0x7f, 0x19, 0x64, 0x6a, 0x59, 0xcc, 0x66, 0x7e, 0xac, 0xee, 0x0e,
	0x9d, 0xb0, 0x78, 0xab, 0xe7, 0xd8, 0xbd, 0x15, 0xaf, 0x41, 0x27, 0xac, 0xa0, 0xc1, 0xce, 0xec,
	0x72, 0xf1, 0x43, 0xc8, 0x2f, 0x85, 0x36, 0x88, 0xf3, 0x48, 0x94, 0x16, 0x9c, 0xb9, 0xcc, 0x06,
	0x75, 0x58, 0xea, 0x6c, 0xe5, 0x02, 0xd2, 0xec, 0x59, 0x88, 0xdf, 0x59, 0x99, 0xf1, 0x7f, 0x46,
	0xab, 0xfc, 0xfd, 0xfb, 0x6f, 0x3f, 0x25, 0xca, 0x79, 0xf8, 0xbf, 0x76, 0x81, 0x08, 0xce, 0xfa,
	0xaf, 0xe8, 0xfa, 0x46, 0x95, 0x5e, 0xdc, 0xa8, 0xd2, 0xcb, 0x1b, 0x15, 0x7d, 0x33, 0x55, 0xd1,
	0x2f, 0x53, 0x15, 0x3d, 0x9f, 0xaa, 0xe8, 0x7a, 0xaa, 0xa2, 0x3f, 0xa7, 0x2a, 0xfa, 0x6b, 0xaa,
	0x4a, 0x2f, 0xa7, 0x2a, 0xfa, 0xe1, 0x56, 0x95, 0xae, 0x6f, 0x55, 0xe9, 0xc5, 0xad, 0x2a, 0xc1,
	0xa1, 0xe5, 0x4e, 0xb4, 0x91, 0xeb, 0x8e, 0x6c, 0xb6, 0xf2, 0xd8, 0xfa, 0x47, 0xb1, 0xae, 0xdc,
	0xf1, 0x7c, 0x57, 0x78, 0xbe, 0xfa, 0x6c, 0xc4, 0xc3, 0x71, 0xf4, 0x44, 0xb3, 0xdc, 0x49, 0x39,
	0xe1, 0x29, 0x2f, 0x3f, 0xa0, 0xaf, 0xfb, 0x68, 0xff, 0x13, 0x00, 0x00, 0xff, 0xff, 0x99, 0xa0,
	0x34, 0x83, 0xd3, 0x07, 0x00, 0x00,
}

func (x InferenceCalculatorOptions_Delegate_Gpu_Api) String() string {
	s, ok := InferenceCalculatorOptions_Delegate_Gpu_Api_name[int32(x)]
	if ok {
		return s
	}
	return strconv.Itoa(int(x))
}
func (x InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior) String() string {
	s, ok := InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior_name[int32(x)]
	if ok {
		return s
	}
	return strconv.Itoa(int(x))
}
func (x InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage) String() string {
	s, ok := InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage_name[int32(x)]
	if ok {
		return s
	}
	return strconv.Itoa(int(x))
}
func (this *InferenceCalculatorOptions) Equal(that interface{}) bool {
	if that == nil {
		return this == nil
	}

	that1, ok := that.(*InferenceCalculatorOptions)
	if !ok {
		that2, ok := that.(InferenceCalculatorOptions)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		return this == nil
	} else if this == nil {
		return false
	}
	if this.ModelPath != that1.ModelPath {
		return false
	}
	if this.UseGpu != nil && that1.UseGpu != nil {
		if *this.UseGpu != *that1.UseGpu {
			return false
		}
	} else if this.UseGpu != nil {
		return false
	} else if that1.UseGpu != nil {
		return false
	}
	if this.UseNnapi != nil && that1.UseNnapi != nil {
		if *this.UseNnapi != *that1.UseNnapi {
			return false
		}
	} else if this.UseNnapi != nil {
		return false
	} else if that1.UseNnapi != nil {
		return false
	}
	if this.CpuNumThread != nil && that1.CpuNumThread != nil {
		if *this.CpuNumThread != *that1.CpuNumThread {
			return false
		}
	} else if this.CpuNumThread != nil {
		return false
	} else if that1.CpuNumThread != nil {
		return false
	}
	if !this.Delegate.Equal(that1.Delegate) {
		return false
	}
	return true
}
func (this *InferenceCalculatorOptions_Delegate) Equal(that interface{}) bool {
	if that == nil {
		return this == nil
	}

	that1, ok := that.(*InferenceCalculatorOptions_Delegate)
	if !ok {
		that2, ok := that.(InferenceCalculatorOptions_Delegate)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		return this == nil
	} else if this == nil {
		return false
	}
	if that1.Delegate == nil {
		if this.Delegate != nil {
			return false
		}
	} else if this.Delegate == nil {
		return false
	} else if !this.Delegate.Equal(that1.Delegate) {
		return false
	}
	return true
}
func (this *InferenceCalculatorOptions_Delegate_Tflite) Equal(that interface{}) bool {
	if that == nil {
		return this == nil
	}

	that1, ok := that.(*InferenceCalculatorOptions_Delegate_Tflite)
	if !ok {
		that2, ok := that.(InferenceCalculatorOptions_Delegate_Tflite)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		return this == nil
	} else if this == nil {
		return false
	}
	if !this.Tflite.Equal(that1.Tflite) {
		return false
	}
	return true
}
func (this *InferenceCalculatorOptions_Delegate_Gpu_) Equal(that interface{}) bool {
	if that == nil {
		return this == nil
	}

	that1, ok := that.(*InferenceCalculatorOptions_Delegate_Gpu_)
	if !ok {
		that2, ok := that.(InferenceCalculatorOptions_Delegate_Gpu_)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		return this == nil
	} else if this == nil {
		return false
	}
	if !this.Gpu.Equal(that1.Gpu) {
		return false
	}
	return true
}
func (this *InferenceCalculatorOptions_Delegate_Nnapi_) Equal(that interface{}) bool {
	if that == nil {
		return this == nil
	}

	that1, ok := that.(*InferenceCalculatorOptions_Delegate_Nnapi_)
	if !ok {
		that2, ok := that.(InferenceCalculatorOptions_Delegate_Nnapi_)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		return this == nil
	} else if this == nil {
		return false
	}
	if !this.Nnapi.Equal(that1.Nnapi) {
		return false
	}
	return true
}
func (this *InferenceCalculatorOptions_Delegate_Xnnpack_) Equal(that interface{}) bool {
	if that == nil {
		return this == nil
	}

	that1, ok := that.(*InferenceCalculatorOptions_Delegate_Xnnpack_)
	if !ok {
		that2, ok := that.(InferenceCalculatorOptions_Delegate_Xnnpack_)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		return this == nil
	} else if this == nil {
		return false
	}
	if !this.Xnnpack.Equal(that1.Xnnpack) {
		return false
	}
	return true
}
func (this *InferenceCalculatorOptions_Delegate_TfLite) Equal(that interface{}) bool {
	if that == nil {
		return this == nil
	}

	that1, ok := that.(*InferenceCalculatorOptions_Delegate_TfLite)
	if !ok {
		that2, ok := that.(InferenceCalculatorOptions_Delegate_TfLite)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		return this == nil
	} else if this == nil {
		return false
	}
	return true
}
func (this *InferenceCalculatorOptions_Delegate_Gpu) Equal(that interface{}) bool {
	if that == nil {
		return this == nil
	}

	that1, ok := that.(*InferenceCalculatorOptions_Delegate_Gpu)
	if !ok {
		that2, ok := that.(InferenceCalculatorOptions_Delegate_Gpu)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		return this == nil
	} else if this == nil {
		return false
	}
	if this.UseAdvancedGpuApi != nil && that1.UseAdvancedGpuApi != nil {
		if *this.UseAdvancedGpuApi != *that1.UseAdvancedGpuApi {
			return false
		}
	} else if this.UseAdvancedGpuApi != nil {
		return false
	} else if that1.UseAdvancedGpuApi != nil {
		return false
	}
	if this.Api != nil && that1.Api != nil {
		if *this.Api != *that1.Api {
			return false
		}
	} else if this.Api != nil {
		return false
	} else if that1.Api != nil {
		return false
	}
	if this.AllowPrecisionLoss != nil && that1.AllowPrecisionLoss != nil {
		if *this.AllowPrecisionLoss != *that1.AllowPrecisionLoss {
			return false
		}
	} else if this.AllowPrecisionLoss != nil {
		return false
	} else if that1.AllowPrecisionLoss != nil {
		return false
	}
	if this.CachedKernelPath != that1.CachedKernelPath {
		return false
	}
	if this.SerializedModelDir != that1.SerializedModelDir {
		return false
	}
	if this.CacheWritingBehavior != nil && that1.CacheWritingBehavior != nil {
		if *this.CacheWritingBehavior != *that1.CacheWritingBehavior {
			return false
		}
	} else if this.CacheWritingBehavior != nil {
		return false
	} else if that1.CacheWritingBehavior != nil {
		return false
	}
	if this.ModelToken != that1.ModelToken {
		return false
	}
	if this.Usage != nil && that1.Usage != nil {
		if *this.Usage != *that1.Usage {
			return false
		}
	} else if this.Usage != nil {
		return false
	} else if that1.Usage != nil {
		return false
	}
	return true
}
func (this *InferenceCalculatorOptions_Delegate_Nnapi) Equal(that interface{}) bool {
	if that == nil {
		return this == nil
	}

	that1, ok := that.(*InferenceCalculatorOptions_Delegate_Nnapi)
	if !ok {
		that2, ok := that.(InferenceCalculatorOptions_Delegate_Nnapi)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		return this == nil
	} else if this == nil {
		return false
	}
	if this.CacheDir != that1.CacheDir {
		return false
	}
	if this.ModelToken != that1.ModelToken {
		return false
	}
	if this.AcceleratorName != that1.AcceleratorName {
		return false
	}
	return true
}
func (this *InferenceCalculatorOptions_Delegate_Xnnpack) Equal(that interface{}) bool {
	if that == nil {
		return this == nil
	}

	that1, ok := that.(*InferenceCalculatorOptions_Delegate_Xnnpack)
	if !ok {
		that2, ok := that.(InferenceCalculatorOptions_Delegate_Xnnpack)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		return this == nil
	} else if this == nil {
		return false
	}
	if this.NumThreads != nil && that1.NumThreads != nil {
		if *this.NumThreads != *that1.NumThreads {
			return false
		}
	} else if this.NumThreads != nil {
		return false
	} else if that1.NumThreads != nil {
		return false
	}
	return true
}
func (this *InferenceCalculatorOptions) GoString() string {
	if this == nil {
		return "nil"
	}
	s := make([]string, 0, 9)
	s = append(s, "&tensor.InferenceCalculatorOptions{")
	s = append(s, "ModelPath: "+fmt.Sprintf("%#v", this.ModelPath)+",\n")
	if this.UseGpu != nil {
		s = append(s, "UseGpu: "+valueToGoStringInferenceCalculator(this.UseGpu, "bool")+",\n")
	}
	if this.UseNnapi != nil {
		s = append(s, "UseNnapi: "+valueToGoStringInferenceCalculator(this.UseNnapi, "bool")+",\n")
	}
	if this.CpuNumThread != nil {
		s = append(s, "CpuNumThread: "+valueToGoStringInferenceCalculator(this.CpuNumThread, "int32")+",\n")
	}
	if this.Delegate != nil {
		s = append(s, "Delegate: "+fmt.Sprintf("%#v", this.Delegate)+",\n")
	}
	s = append(s, "}")
	return strings.Join(s, "")
}
func (this *InferenceCalculatorOptions_Delegate) GoString() string {
	if this == nil {
		return "nil"
	}
	s := make([]string, 0, 8)
	s = append(s, "&tensor.InferenceCalculatorOptions_Delegate{")
	if this.Delegate != nil {
		s = append(s, "Delegate: "+fmt.Sprintf("%#v", this.Delegate)+",\n")
	}
	s = append(s, "}")
	return strings.Join(s, "")
}
func (this *InferenceCalculatorOptions_Delegate_Tflite) GoString() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&tensor.InferenceCalculatorOptions_Delegate_Tflite{` +
		`Tflite:` + fmt.Sprintf("%#v", this.Tflite) + `}`}, ", ")
	return s
}
func (this *InferenceCalculatorOptions_Delegate_Gpu_) GoString() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&tensor.InferenceCalculatorOptions_Delegate_Gpu_{` +
		`Gpu:` + fmt.Sprintf("%#v", this.Gpu) + `}`}, ", ")
	return s
}
func (this *InferenceCalculatorOptions_Delegate_Nnapi_) GoString() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&tensor.InferenceCalculatorOptions_Delegate_Nnapi_{` +
		`Nnapi:` + fmt.Sprintf("%#v", this.Nnapi) + `}`}, ", ")
	return s
}
func (this *InferenceCalculatorOptions_Delegate_Xnnpack_) GoString() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&tensor.InferenceCalculatorOptions_Delegate_Xnnpack_{` +
		`Xnnpack:` + fmt.Sprintf("%#v", this.Xnnpack) + `}`}, ", ")
	return s
}
func (this *InferenceCalculatorOptions_Delegate_TfLite) GoString() string {
	if this == nil {
		return "nil"
	}
	s := make([]string, 0, 4)
	s = append(s, "&tensor.InferenceCalculatorOptions_Delegate_TfLite{")
	s = append(s, "}")
	return strings.Join(s, "")
}
func (this *InferenceCalculatorOptions_Delegate_Gpu) GoString() string {
	if this == nil {
		return "nil"
	}
	s := make([]string, 0, 12)
	s = append(s, "&tensor.InferenceCalculatorOptions_Delegate_Gpu{")
	if this.UseAdvancedGpuApi != nil {
		s = append(s, "UseAdvancedGpuApi: "+valueToGoStringInferenceCalculator(this.UseAdvancedGpuApi, "bool")+",\n")
	}
	if this.Api != nil {
		s = append(s, "Api: "+valueToGoStringInferenceCalculator(this.Api, "InferenceCalculatorOptions_Delegate_Gpu_Api")+",\n")
	}
	if this.AllowPrecisionLoss != nil {
		s = append(s, "AllowPrecisionLoss: "+valueToGoStringInferenceCalculator(this.AllowPrecisionLoss, "bool")+",\n")
	}
	s = append(s, "CachedKernelPath: "+fmt.Sprintf("%#v", this.CachedKernelPath)+",\n")
	s = append(s, "SerializedModelDir: "+fmt.Sprintf("%#v", this.SerializedModelDir)+",\n")
	if this.CacheWritingBehavior != nil {
		s = append(s, "CacheWritingBehavior: "+valueToGoStringInferenceCalculator(this.CacheWritingBehavior, "InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior")+",\n")
	}
	s = append(s, "ModelToken: "+fmt.Sprintf("%#v", this.ModelToken)+",\n")
	if this.Usage != nil {
		s = append(s, "Usage: "+valueToGoStringInferenceCalculator(this.Usage, "InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage")+",\n")
	}
	s = append(s, "}")
	return strings.Join(s, "")
}
func (this *InferenceCalculatorOptions_Delegate_Nnapi) GoString() string {
	if this == nil {
		return "nil"
	}
	s := make([]string, 0, 7)
	s = append(s, "&tensor.InferenceCalculatorOptions_Delegate_Nnapi{")
	s = append(s, "CacheDir: "+fmt.Sprintf("%#v", this.CacheDir)+",\n")
	s = append(s, "ModelToken: "+fmt.Sprintf("%#v", this.ModelToken)+",\n")
	s = append(s, "AcceleratorName: "+fmt.Sprintf("%#v", this.AcceleratorName)+",\n")
	s = append(s, "}")
	return strings.Join(s, "")
}
func (this *InferenceCalculatorOptions_Delegate_Xnnpack) GoString() string {
	if this == nil {
		return "nil"
	}
	s := make([]string, 0, 5)
	s = append(s, "&tensor.InferenceCalculatorOptions_Delegate_Xnnpack{")
	if this.NumThreads != nil {
		s = append(s, "NumThreads: "+valueToGoStringInferenceCalculator(this.NumThreads, "int32")+",\n")
	}
	s = append(s, "}")
	return strings.Join(s, "")
}
func valueToGoStringInferenceCalculator(v interface{}, typ string) string {
	rv := reflect.ValueOf(v)
	if rv.IsNil() {
		return "nil"
	}
	pv := reflect.Indirect(rv).Interface()
	return fmt.Sprintf("func(v %v) *%v { return &v } ( %#v )", typ, typ, pv)
}
func (m *InferenceCalculatorOptions) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *InferenceCalculatorOptions) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *InferenceCalculatorOptions) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.Delegate != nil {
		{
			size, err := m.Delegate.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintInferenceCalculator(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2a
	}
	if m.CpuNumThread != nil {
		i = encodeVarintInferenceCalculator(dAtA, i, uint64(*m.CpuNumThread))
		i--
		dAtA[i] = 0x20
	}
	if m.UseNnapi != nil {
		i--
		if *m.UseNnapi {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x18
	}
	if m.UseGpu != nil {
		i--
		if *m.UseGpu {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x10
	}
	i -= len(m.ModelPath)
	copy(dAtA[i:], m.ModelPath)
	i = encodeVarintInferenceCalculator(dAtA, i, uint64(len(m.ModelPath)))
	i--
	dAtA[i] = 0xa
	return len(dAtA) - i, nil
}

func (m *InferenceCalculatorOptions_Delegate) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *InferenceCalculatorOptions_Delegate) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *InferenceCalculatorOptions_Delegate) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.Delegate != nil {
		{
			size := m.Delegate.Size()
			i -= size
			if _, err := m.Delegate.MarshalTo(dAtA[i:]); err != nil {
				return 0, err
			}
		}
	}
	return len(dAtA) - i, nil
}

func (m *InferenceCalculatorOptions_Delegate_Tflite) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *InferenceCalculatorOptions_Delegate_Tflite) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.Tflite != nil {
		{
			size, err := m.Tflite.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintInferenceCalculator(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}
func (m *InferenceCalculatorOptions_Delegate_Gpu_) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *InferenceCalculatorOptions_Delegate_Gpu_) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.Gpu != nil {
		{
			size, err := m.Gpu.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintInferenceCalculator(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x12
	}
	return len(dAtA) - i, nil
}
func (m *InferenceCalculatorOptions_Delegate_Nnapi_) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *InferenceCalculatorOptions_Delegate_Nnapi_) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.Nnapi != nil {
		{
			size, err := m.Nnapi.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintInferenceCalculator(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1a
	}
	return len(dAtA) - i, nil
}
func (m *InferenceCalculatorOptions_Delegate_Xnnpack_) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *InferenceCalculatorOptions_Delegate_Xnnpack_) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.Xnnpack != nil {
		{
			size, err := m.Xnnpack.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintInferenceCalculator(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x22
	}
	return len(dAtA) - i, nil
}
func (m *InferenceCalculatorOptions_Delegate_TfLite) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *InferenceCalculatorOptions_Delegate_TfLite) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *InferenceCalculatorOptions_Delegate_TfLite) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *InferenceCalculatorOptions_Delegate_Gpu) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *InferenceCalculatorOptions_Delegate_Gpu) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *InferenceCalculatorOptions_Delegate_Gpu) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.CacheWritingBehavior != nil {
		i = encodeVarintInferenceCalculator(dAtA, i, uint64(*m.CacheWritingBehavior))
		i--
		dAtA[i] = 0x50
	}
	i -= len(m.ModelToken)
	copy(dAtA[i:], m.ModelToken)
	i = encodeVarintInferenceCalculator(dAtA, i, uint64(len(m.ModelToken)))
	i--
	dAtA[i] = 0x42
	i -= len(m.SerializedModelDir)
	copy(dAtA[i:], m.SerializedModelDir)
	i = encodeVarintInferenceCalculator(dAtA, i, uint64(len(m.SerializedModelDir)))
	i--
	dAtA[i] = 0x3a
	if m.Usage != nil {
		i = encodeVarintInferenceCalculator(dAtA, i, uint64(*m.Usage))
		i--
		dAtA[i] = 0x28
	}
	if m.Api != nil {
		i = encodeVarintInferenceCalculator(dAtA, i, uint64(*m.Api))
		i--
		dAtA[i] = 0x20
	}
	if m.AllowPrecisionLoss != nil {
		i--
		if *m.AllowPrecisionLoss {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x18
	}
	i -= len(m.CachedKernelPath)
	copy(dAtA[i:], m.CachedKernelPath)
	i = encodeVarintInferenceCalculator(dAtA, i, uint64(len(m.CachedKernelPath)))
	i--
	dAtA[i] = 0x12
	if m.UseAdvancedGpuApi != nil {
		i--
		if *m.UseAdvancedGpuApi {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *InferenceCalculatorOptions_Delegate_Nnapi) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *InferenceCalculatorOptions_Delegate_Nnapi) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *InferenceCalculatorOptions_Delegate_Nnapi) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	i -= len(m.AcceleratorName)
	copy(dAtA[i:], m.AcceleratorName)
	i = encodeVarintInferenceCalculator(dAtA, i, uint64(len(m.AcceleratorName)))
	i--
	dAtA[i] = 0x1a
	i -= len(m.ModelToken)
	copy(dAtA[i:], m.ModelToken)
	i = encodeVarintInferenceCalculator(dAtA, i, uint64(len(m.ModelToken)))
	i--
	dAtA[i] = 0x12
	i -= len(m.CacheDir)
	copy(dAtA[i:], m.CacheDir)
	i = encodeVarintInferenceCalculator(dAtA, i, uint64(len(m.CacheDir)))
	i--
	dAtA[i] = 0xa
	return len(dAtA) - i, nil
}

func (m *InferenceCalculatorOptions_Delegate_Xnnpack) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *InferenceCalculatorOptions_Delegate_Xnnpack) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *InferenceCalculatorOptions_Delegate_Xnnpack) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.NumThreads != nil {
		i = encodeVarintInferenceCalculator(dAtA, i, uint64(*m.NumThreads))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func encodeVarintInferenceCalculator(dAtA []byte, offset int, v uint64) int {
	offset -= sovInferenceCalculator(v)
	base := offset
	for v >= 1<<7 {
		dAtA[offset] = uint8(v&0x7f | 0x80)
		v >>= 7
		offset++
	}
	dAtA[offset] = uint8(v)
	return base
}
func (m *InferenceCalculatorOptions) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.ModelPath)
	n += 1 + l + sovInferenceCalculator(uint64(l))
	if m.UseGpu != nil {
		n += 2
	}
	if m.UseNnapi != nil {
		n += 2
	}
	if m.CpuNumThread != nil {
		n += 1 + sovInferenceCalculator(uint64(*m.CpuNumThread))
	}
	if m.Delegate != nil {
		l = m.Delegate.Size()
		n += 1 + l + sovInferenceCalculator(uint64(l))
	}
	return n
}

func (m *InferenceCalculatorOptions_Delegate) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Delegate != nil {
		n += m.Delegate.Size()
	}
	return n
}

func (m *InferenceCalculatorOptions_Delegate_Tflite) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Tflite != nil {
		l = m.Tflite.Size()
		n += 1 + l + sovInferenceCalculator(uint64(l))
	}
	return n
}
func (m *InferenceCalculatorOptions_Delegate_Gpu_) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Gpu != nil {
		l = m.Gpu.Size()
		n += 1 + l + sovInferenceCalculator(uint64(l))
	}
	return n
}
func (m *InferenceCalculatorOptions_Delegate_Nnapi_) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Nnapi != nil {
		l = m.Nnapi.Size()
		n += 1 + l + sovInferenceCalculator(uint64(l))
	}
	return n
}
func (m *InferenceCalculatorOptions_Delegate_Xnnpack_) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Xnnpack != nil {
		l = m.Xnnpack.Size()
		n += 1 + l + sovInferenceCalculator(uint64(l))
	}
	return n
}
func (m *InferenceCalculatorOptions_Delegate_TfLite) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *InferenceCalculatorOptions_Delegate_Gpu) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.UseAdvancedGpuApi != nil {
		n += 2
	}
	l = len(m.CachedKernelPath)
	n += 1 + l + sovInferenceCalculator(uint64(l))
	if m.AllowPrecisionLoss != nil {
		n += 2
	}
	if m.Api != nil {
		n += 1 + sovInferenceCalculator(uint64(*m.Api))
	}
	if m.Usage != nil {
		n += 1 + sovInferenceCalculator(uint64(*m.Usage))
	}
	l = len(m.SerializedModelDir)
	n += 1 + l + sovInferenceCalculator(uint64(l))
	l = len(m.ModelToken)
	n += 1 + l + sovInferenceCalculator(uint64(l))
	if m.CacheWritingBehavior != nil {
		n += 1 + sovInferenceCalculator(uint64(*m.CacheWritingBehavior))
	}
	return n
}

func (m *InferenceCalculatorOptions_Delegate_Nnapi) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.CacheDir)
	n += 1 + l + sovInferenceCalculator(uint64(l))
	l = len(m.ModelToken)
	n += 1 + l + sovInferenceCalculator(uint64(l))
	l = len(m.AcceleratorName)
	n += 1 + l + sovInferenceCalculator(uint64(l))
	return n
}

func (m *InferenceCalculatorOptions_Delegate_Xnnpack) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.NumThreads != nil {
		n += 1 + sovInferenceCalculator(uint64(*m.NumThreads))
	}
	return n
}

func sovInferenceCalculator(x uint64) (n int) {
	return (math_bits.Len64(x|1) + 6) / 7
}
func sozInferenceCalculator(x uint64) (n int) {
	return sovInferenceCalculator(uint64((x << 1) ^ uint64((int64(x) >> 63))))
}
func (this *InferenceCalculatorOptions) String() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&InferenceCalculatorOptions{`,
		`ModelPath:` + fmt.Sprintf("%v", this.ModelPath) + `,`,
		`UseGpu:` + valueToStringInferenceCalculator(this.UseGpu) + `,`,
		`UseNnapi:` + valueToStringInferenceCalculator(this.UseNnapi) + `,`,
		`CpuNumThread:` + valueToStringInferenceCalculator(this.CpuNumThread) + `,`,
		`Delegate:` + strings.Replace(fmt.Sprintf("%v", this.Delegate), "InferenceCalculatorOptions_Delegate", "InferenceCalculatorOptions_Delegate", 1) + `,`,
		`}`,
	}, "")
	return s
}
func (this *InferenceCalculatorOptions_Delegate) String() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&InferenceCalculatorOptions_Delegate{`,
		`Delegate:` + fmt.Sprintf("%v", this.Delegate) + `,`,
		`}`,
	}, "")
	return s
}
func (this *InferenceCalculatorOptions_Delegate_Tflite) String() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&InferenceCalculatorOptions_Delegate_Tflite{`,
		`Tflite:` + strings.Replace(fmt.Sprintf("%v", this.Tflite), "InferenceCalculatorOptions_Delegate_TfLite", "InferenceCalculatorOptions_Delegate_TfLite", 1) + `,`,
		`}`,
	}, "")
	return s
}
func (this *InferenceCalculatorOptions_Delegate_Gpu_) String() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&InferenceCalculatorOptions_Delegate_Gpu_{`,
		`Gpu:` + strings.Replace(fmt.Sprintf("%v", this.Gpu), "InferenceCalculatorOptions_Delegate_Gpu", "InferenceCalculatorOptions_Delegate_Gpu", 1) + `,`,
		`}`,
	}, "")
	return s
}
func (this *InferenceCalculatorOptions_Delegate_Nnapi_) String() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&InferenceCalculatorOptions_Delegate_Nnapi_{`,
		`Nnapi:` + strings.Replace(fmt.Sprintf("%v", this.Nnapi), "InferenceCalculatorOptions_Delegate_Nnapi", "InferenceCalculatorOptions_Delegate_Nnapi", 1) + `,`,
		`}`,
	}, "")
	return s
}
func (this *InferenceCalculatorOptions_Delegate_Xnnpack_) String() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&InferenceCalculatorOptions_Delegate_Xnnpack_{`,
		`Xnnpack:` + strings.Replace(fmt.Sprintf("%v", this.Xnnpack), "InferenceCalculatorOptions_Delegate_Xnnpack", "InferenceCalculatorOptions_Delegate_Xnnpack", 1) + `,`,
		`}`,
	}, "")
	return s
}
func (this *InferenceCalculatorOptions_Delegate_TfLite) String() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&InferenceCalculatorOptions_Delegate_TfLite{`,
		`}`,
	}, "")
	return s
}
func (this *InferenceCalculatorOptions_Delegate_Gpu) String() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&InferenceCalculatorOptions_Delegate_Gpu{`,
		`UseAdvancedGpuApi:` + valueToStringInferenceCalculator(this.UseAdvancedGpuApi) + `,`,
		`CachedKernelPath:` + fmt.Sprintf("%v", this.CachedKernelPath) + `,`,
		`AllowPrecisionLoss:` + valueToStringInferenceCalculator(this.AllowPrecisionLoss) + `,`,
		`Api:` + valueToStringInferenceCalculator(this.Api) + `,`,
		`Usage:` + valueToStringInferenceCalculator(this.Usage) + `,`,
		`SerializedModelDir:` + fmt.Sprintf("%v", this.SerializedModelDir) + `,`,
		`ModelToken:` + fmt.Sprintf("%v", this.ModelToken) + `,`,
		`CacheWritingBehavior:` + valueToStringInferenceCalculator(this.CacheWritingBehavior) + `,`,
		`}`,
	}, "")
	return s
}
func (this *InferenceCalculatorOptions_Delegate_Nnapi) String() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&InferenceCalculatorOptions_Delegate_Nnapi{`,
		`CacheDir:` + fmt.Sprintf("%v", this.CacheDir) + `,`,
		`ModelToken:` + fmt.Sprintf("%v", this.ModelToken) + `,`,
		`AcceleratorName:` + fmt.Sprintf("%v", this.AcceleratorName) + `,`,
		`}`,
	}, "")
	return s
}
func (this *InferenceCalculatorOptions_Delegate_Xnnpack) String() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&InferenceCalculatorOptions_Delegate_Xnnpack{`,
		`NumThreads:` + valueToStringInferenceCalculator(this.NumThreads) + `,`,
		`}`,
	}, "")
	return s
}
func valueToStringInferenceCalculator(v interface{}) string {
	rv := reflect.ValueOf(v)
	if rv.IsNil() {
		return "nil"
	}
	pv := reflect.Indirect(rv).Interface()
	return fmt.Sprintf("*%v", pv)
}
func (m *InferenceCalculatorOptions) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowInferenceCalculator
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: InferenceCalculatorOptions: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: InferenceCalculatorOptions: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ModelPath", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowInferenceCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.ModelPath = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field UseGpu", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowInferenceCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			b := bool(v != 0)
			m.UseGpu = &b
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field UseNnapi", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowInferenceCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			b := bool(v != 0)
			m.UseNnapi = &b
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field CpuNumThread", wireType)
			}
			var v int32
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowInferenceCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int32(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.CpuNumThread = &v
		case 5:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Delegate", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowInferenceCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Delegate == nil {
				m.Delegate = &InferenceCalculatorOptions_Delegate{}
			}
			if err := m.Delegate.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipInferenceCalculator(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *InferenceCalculatorOptions_Delegate) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowInferenceCalculator
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: Delegate: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: Delegate: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Tflite", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowInferenceCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &InferenceCalculatorOptions_Delegate_TfLite{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Delegate = &InferenceCalculatorOptions_Delegate_Tflite{v}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Gpu", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowInferenceCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &InferenceCalculatorOptions_Delegate_Gpu{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Delegate = &InferenceCalculatorOptions_Delegate_Gpu_{v}
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Nnapi", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowInferenceCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &InferenceCalculatorOptions_Delegate_Nnapi{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Delegate = &InferenceCalculatorOptions_Delegate_Nnapi_{v}
			iNdEx = postIndex
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Xnnpack", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowInferenceCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &InferenceCalculatorOptions_Delegate_Xnnpack{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Delegate = &InferenceCalculatorOptions_Delegate_Xnnpack_{v}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipInferenceCalculator(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *InferenceCalculatorOptions_Delegate_TfLite) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowInferenceCalculator
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: TfLite: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: TfLite: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipInferenceCalculator(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *InferenceCalculatorOptions_Delegate_Gpu) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowInferenceCalculator
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: Gpu: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: Gpu: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field UseAdvancedGpuApi", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowInferenceCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			b := bool(v != 0)
			m.UseAdvancedGpuApi = &b
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field CachedKernelPath", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowInferenceCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.CachedKernelPath = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field AllowPrecisionLoss", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowInferenceCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			b := bool(v != 0)
			m.AllowPrecisionLoss = &b
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Api", wireType)
			}
			var v InferenceCalculatorOptions_Delegate_Gpu_Api
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowInferenceCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= InferenceCalculatorOptions_Delegate_Gpu_Api(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.Api = &v
		case 5:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Usage", wireType)
			}
			var v InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowInferenceCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.Usage = &v
		case 7:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SerializedModelDir", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowInferenceCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.SerializedModelDir = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 8:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ModelToken", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowInferenceCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.ModelToken = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 10:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field CacheWritingBehavior", wireType)
			}
			var v InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowInferenceCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= InferenceCalculatorOptions_Delegate_Gpu_CacheWritingBehavior(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.CacheWritingBehavior = &v
		default:
			iNdEx = preIndex
			skippy, err := skipInferenceCalculator(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *InferenceCalculatorOptions_Delegate_Nnapi) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowInferenceCalculator
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: Nnapi: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: Nnapi: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field CacheDir", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowInferenceCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.CacheDir = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ModelToken", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowInferenceCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.ModelToken = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field AcceleratorName", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowInferenceCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.AcceleratorName = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipInferenceCalculator(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *InferenceCalculatorOptions_Delegate_Xnnpack) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowInferenceCalculator
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: Xnnpack: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: Xnnpack: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field NumThreads", wireType)
			}
			var v int32
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowInferenceCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int32(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.NumThreads = &v
		default:
			iNdEx = preIndex
			skippy, err := skipInferenceCalculator(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthInferenceCalculator
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func skipInferenceCalculator(dAtA []byte) (n int, err error) {
	l := len(dAtA)
	iNdEx := 0
	depth := 0
	for iNdEx < l {
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return 0, ErrIntOverflowInferenceCalculator
			}
			if iNdEx >= l {
				return 0, io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		wireType := int(wire & 0x7)
		switch wireType {
		case 0:
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowInferenceCalculator
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				iNdEx++
				if dAtA[iNdEx-1] < 0x80 {
					break
				}
			}
		case 1:
			iNdEx += 8
		case 2:
			var length int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowInferenceCalculator
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				length |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if length < 0 {
				return 0, ErrInvalidLengthInferenceCalculator
			}
			iNdEx += length
		case 3:
			depth++
		case 4:
			if depth == 0 {
				return 0, ErrUnexpectedEndOfGroupInferenceCalculator
			}
			depth--
		case 5:
			iNdEx += 4
		default:
			return 0, fmt.Errorf("proto: illegal wireType %d", wireType)
		}
		if iNdEx < 0 {
			return 0, ErrInvalidLengthInferenceCalculator
		}
		if depth == 0 {
			return iNdEx, nil
		}
	}
	return 0, io.ErrUnexpectedEOF
}

var (
	ErrInvalidLengthInferenceCalculator        = fmt.Errorf("proto: negative length found during unmarshaling")
	ErrIntOverflowInferenceCalculator          = fmt.Errorf("proto: integer overflow")
	ErrUnexpectedEndOfGroupInferenceCalculator = fmt.Errorf("proto: unexpected end of group")
)
