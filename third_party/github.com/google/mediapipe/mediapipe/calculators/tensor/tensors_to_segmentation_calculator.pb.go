// Code generated by protoc-gen-gogo. DO NOT EDIT.
// source: mediapipe/calculators/tensor/tensors_to_segmentation_calculator.proto

package tensor

import (
	fmt "fmt"
	proto "github.com/gogo/protobuf/proto"
	framework "github.com/google/mediapipe/mediapipe/framework"
	gpu "github.com/google/mediapipe/mediapipe/gpu"
	io "io"
	math "math"
	math_bits "math/bits"
	reflect "reflect"
	strconv "strconv"
	strings "strings"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.GoGoProtoPackageIsVersion3 // please upgrade the proto package

type TensorsToSegmentationCalculatorOptions_Activation int32

const (
	NONE    TensorsToSegmentationCalculatorOptions_Activation = 0
	SIGMOID TensorsToSegmentationCalculatorOptions_Activation = 1
	SOFTMAX TensorsToSegmentationCalculatorOptions_Activation = 2
)

var TensorsToSegmentationCalculatorOptions_Activation_name = map[int32]string{
	0: "NONE",
	1: "SIGMOID",
	2: "SOFTMAX",
}

var TensorsToSegmentationCalculatorOptions_Activation_value = map[string]int32{
	"NONE":    0,
	"SIGMOID": 1,
	"SOFTMAX": 2,
}

func (x TensorsToSegmentationCalculatorOptions_Activation) Enum() *TensorsToSegmentationCalculatorOptions_Activation {
	p := new(TensorsToSegmentationCalculatorOptions_Activation)
	*p = x
	return p
}

func (x TensorsToSegmentationCalculatorOptions_Activation) MarshalJSON() ([]byte, error) {
	return proto.MarshalJSONEnum(TensorsToSegmentationCalculatorOptions_Activation_name, int32(x))
}

func (x *TensorsToSegmentationCalculatorOptions_Activation) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(TensorsToSegmentationCalculatorOptions_Activation_value, data, "TensorsToSegmentationCalculatorOptions_Activation")
	if err != nil {
		return err
	}
	*x = TensorsToSegmentationCalculatorOptions_Activation(value)
	return nil
}

func (TensorsToSegmentationCalculatorOptions_Activation) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_2c3f117ccb503e0d, []int{0, 0}
}

type TensorsToSegmentationCalculatorOptions struct {
	GpuOrigin        gpu.GpuOrigin_Mode                                 `protobuf:"varint,1,opt,name=gpu_origin,json=gpuOrigin,enum=mediapipe.GpuOrigin_Mode" json:"gpu_origin"`
	Activation       *TensorsToSegmentationCalculatorOptions_Activation `protobuf:"varint,2,opt,name=activation,enum=mediapipe.TensorsToSegmentationCalculatorOptions_Activation,def=0" json:"activation,omitempty"`
	OutputLayerIndex *int32                                             `protobuf:"varint,3,opt,name=output_layer_index,json=outputLayerIndex,def=1" json:"output_layer_index,omitempty"`
}

func (m *TensorsToSegmentationCalculatorOptions) Reset() {
	*m = TensorsToSegmentationCalculatorOptions{}
}
func (*TensorsToSegmentationCalculatorOptions) ProtoMessage() {}
func (*TensorsToSegmentationCalculatorOptions) Descriptor() ([]byte, []int) {
	return fileDescriptor_2c3f117ccb503e0d, []int{0}
}
func (m *TensorsToSegmentationCalculatorOptions) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *TensorsToSegmentationCalculatorOptions) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_TensorsToSegmentationCalculatorOptions.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *TensorsToSegmentationCalculatorOptions) XXX_Merge(src proto.Message) {
	xxx_messageInfo_TensorsToSegmentationCalculatorOptions.Merge(m, src)
}
func (m *TensorsToSegmentationCalculatorOptions) XXX_Size() int {
	return m.Size()
}
func (m *TensorsToSegmentationCalculatorOptions) XXX_DiscardUnknown() {
	xxx_messageInfo_TensorsToSegmentationCalculatorOptions.DiscardUnknown(m)
}

var xxx_messageInfo_TensorsToSegmentationCalculatorOptions proto.InternalMessageInfo

const Default_TensorsToSegmentationCalculatorOptions_Activation TensorsToSegmentationCalculatorOptions_Activation = NONE
const Default_TensorsToSegmentationCalculatorOptions_OutputLayerIndex int32 = 1

func (m *TensorsToSegmentationCalculatorOptions) GetGpuOrigin() gpu.GpuOrigin_Mode {
	if m != nil {
		return m.GpuOrigin
	}
	return gpu.ORIGIN_MODE_DEFAULT
}

func (m *TensorsToSegmentationCalculatorOptions) GetActivation() TensorsToSegmentationCalculatorOptions_Activation {
	if m != nil && m.Activation != nil {
		return *m.Activation
	}
	return Default_TensorsToSegmentationCalculatorOptions_Activation
}

func (m *TensorsToSegmentationCalculatorOptions) GetOutputLayerIndex() int32 {
	if m != nil && m.OutputLayerIndex != nil {
		return *m.OutputLayerIndex
	}
	return Default_TensorsToSegmentationCalculatorOptions_OutputLayerIndex
}

var E_TensorsToSegmentationCalculatorOptions_Ext = &proto.ExtensionDesc{
	ExtendedType:  (*framework.CalculatorOptions)(nil),
	ExtensionType: (*TensorsToSegmentationCalculatorOptions)(nil),
	Field:         374311106,
	Name:          "mediapipe.TensorsToSegmentationCalculatorOptions.ext",
	Tag:           "bytes,374311106,opt,name=ext",
	Filename:      "mediapipe/calculators/tensor/tensors_to_segmentation_calculator.proto",
}

func init() {
	proto.RegisterEnum("mediapipe.TensorsToSegmentationCalculatorOptions_Activation", TensorsToSegmentationCalculatorOptions_Activation_name, TensorsToSegmentationCalculatorOptions_Activation_value)
	proto.RegisterExtension(E_TensorsToSegmentationCalculatorOptions_Ext)
	proto.RegisterType((*TensorsToSegmentationCalculatorOptions)(nil), "mediapipe.TensorsToSegmentationCalculatorOptions")
}

func init() {
	proto.RegisterFile("mediapipe/calculators/tensor/tensors_to_segmentation_calculator.proto", fileDescriptor_2c3f117ccb503e0d)
}

var fileDescriptor_2c3f117ccb503e0d = []byte{
	// 404 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0xe2, 0x72, 0xcd, 0x4d, 0x4d, 0xc9,
	0x4c, 0x2c, 0xc8, 0x2c, 0x48, 0xd5, 0x4f, 0x4e, 0xcc, 0x49, 0x2e, 0xcd, 0x49, 0x2c, 0xc9, 0x2f,
	0x2a, 0xd6, 0x2f, 0x49, 0xcd, 0x2b, 0xce, 0x2f, 0x82, 0x52, 0xc5, 0xf1, 0x25, 0xf9, 0xf1, 0xc5,
	0xa9, 0xe9, 0xb9, 0xa9, 0x79, 0x25, 0x89, 0x25, 0x99, 0xf9, 0x79, 0xf1, 0x08, 0xa5, 0x7a, 0x05,
	0x45, 0xf9, 0x25, 0xf9, 0x42, 0x9c, 0x70, 0x63, 0xa4, 0x54, 0x10, 0x26, 0xa6, 0x15, 0x25, 0xe6,
	0xa6, 0x96, 0xe7, 0x17, 0x65, 0xeb, 0xa3, 0x6b, 0x90, 0x92, 0x43, 0xa8, 0x4a, 0x2f, 0x28, 0x05,
	0xe1, 0xf8, 0xfc, 0xa2, 0xcc, 0xf4, 0xcc, 0x3c, 0x88, 0xbc, 0xd2, 0x34, 0x66, 0x2e, 0xb5, 0x10,
	0x88, 0xed, 0x21, 0xf9, 0xc1, 0x48, 0x76, 0x3b, 0xc3, 0x4d, 0xf2, 0x2f, 0x00, 0xf1, 0x8b, 0x85,
	0xec, 0xb8, 0xb8, 0x10, 0xda, 0x25, 0x18, 0x15, 0x18, 0x35, 0xf8, 0x8c, 0x24, 0xf5, 0xe0, 0xe6,
	0xeb, 0xb9, 0x17, 0x94, 0xfa, 0x43, 0x8c, 0xf6, 0xcd, 0x4f, 0x49, 0x75, 0x62, 0x39, 0x71, 0x4f,
	0x9e, 0x21, 0x88, 0x33, 0x1d, 0x26, 0x2a, 0x94, 0xc4, 0xc5, 0x95, 0x98, 0x5c, 0x92, 0x59, 0x06,
	0x36, 0x5e, 0x82, 0x09, 0xac, 0xdf, 0x06, 0x49, 0x3f, 0x71, 0xce, 0xd0, 0x73, 0x84, 0x9b, 0x61,
	0xc5, 0xe2, 0xe7, 0xef, 0xe7, 0x1a, 0x84, 0x64, 0xaa, 0x90, 0x3e, 0x97, 0x50, 0x7e, 0x69, 0x49,
	0x41, 0x69, 0x49, 0x7c, 0x4e, 0x62, 0x65, 0x6a, 0x51, 0x7c, 0x66, 0x5e, 0x4a, 0x6a, 0x85, 0x04,
	0xb3, 0x02, 0xa3, 0x06, 0xab, 0x15, 0xa3, 0x61, 0x90, 0x00, 0x44, 0xd2, 0x07, 0x24, 0xe7, 0x09,
	0x92, 0x52, 0x32, 0xe0, 0xe2, 0x42, 0x18, 0x28, 0xc4, 0xc1, 0x05, 0x36, 0x52, 0x80, 0x41, 0x88,
	0x9b, 0x8b, 0x3d, 0xd8, 0xd3, 0xdd, 0xd7, 0xdf, 0xd3, 0x45, 0x80, 0x11, 0xcc, 0xf1, 0x77, 0x0b,
	0xf1, 0x75, 0x8c, 0x10, 0x60, 0x32, 0x4a, 0xe5, 0x62, 0x4e, 0xad, 0x28, 0x11, 0x92, 0x41, 0x72,
	0x39, 0x86, 0x23, 0x25, 0x0e, 0x4d, 0xdc, 0xb7, 0x09, 0x14, 0x42, 0xdc, 0x46, 0x86, 0x24, 0xfb,
	0x30, 0x08, 0x64, 0xbe, 0x53, 0xde, 0x85, 0x87, 0x72, 0x0c, 0x37, 0x1e, 0xca, 0x31, 0x7c, 0x78,
	0x28, 0xc7, 0xd8, 0xf0, 0x48, 0x8e, 0x71, 0xc5, 0x23, 0x39, 0xc6, 0x13, 0x8f, 0xe4, 0x18, 0x2f,
	0x3c, 0x92, 0x63, 0x7c, 0xf0, 0x48, 0x8e, 0xf1, 0xc5, 0x23, 0x39, 0x86, 0x0f, 0x8f, 0xe4, 0x18,
	0x27, 0x3c, 0x96, 0x63, 0xb8, 0xf0, 0x58, 0x8e, 0xe1, 0xc6, 0x63, 0x39, 0x86, 0x28, 0x8b, 0xf4,
	0xcc, 0x92, 0x8c, 0xd2, 0x24, 0xbd, 0xe4, 0xfc, 0x5c, 0xfd, 0xf4, 0xfc, 0xfc, 0xf4, 0x9c, 0x54,
	0x7d, 0x44, 0x02, 0xc0, 0x97, 0x04, 0x01, 0x01, 0x00, 0x00, 0xff, 0xff, 0xd7, 0xe2, 0xec, 0x13,
	0xa1, 0x02, 0x00, 0x00,
}

func (x TensorsToSegmentationCalculatorOptions_Activation) String() string {
	s, ok := TensorsToSegmentationCalculatorOptions_Activation_name[int32(x)]
	if ok {
		return s
	}
	return strconv.Itoa(int(x))
}
func (this *TensorsToSegmentationCalculatorOptions) Equal(that interface{}) bool {
	if that == nil {
		return this == nil
	}

	that1, ok := that.(*TensorsToSegmentationCalculatorOptions)
	if !ok {
		that2, ok := that.(TensorsToSegmentationCalculatorOptions)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		return this == nil
	} else if this == nil {
		return false
	}
	if this.GpuOrigin != that1.GpuOrigin {
		return false
	}
	if this.Activation != nil && that1.Activation != nil {
		if *this.Activation != *that1.Activation {
			return false
		}
	} else if this.Activation != nil {
		return false
	} else if that1.Activation != nil {
		return false
	}
	if this.OutputLayerIndex != nil && that1.OutputLayerIndex != nil {
		if *this.OutputLayerIndex != *that1.OutputLayerIndex {
			return false
		}
	} else if this.OutputLayerIndex != nil {
		return false
	} else if that1.OutputLayerIndex != nil {
		return false
	}
	return true
}
func (this *TensorsToSegmentationCalculatorOptions) GoString() string {
	if this == nil {
		return "nil"
	}
	s := make([]string, 0, 7)
	s = append(s, "&tensor.TensorsToSegmentationCalculatorOptions{")
	s = append(s, "GpuOrigin: "+fmt.Sprintf("%#v", this.GpuOrigin)+",\n")
	if this.Activation != nil {
		s = append(s, "Activation: "+valueToGoStringTensorsToSegmentationCalculator(this.Activation, "TensorsToSegmentationCalculatorOptions_Activation")+",\n")
	}
	if this.OutputLayerIndex != nil {
		s = append(s, "OutputLayerIndex: "+valueToGoStringTensorsToSegmentationCalculator(this.OutputLayerIndex, "int32")+",\n")
	}
	s = append(s, "}")
	return strings.Join(s, "")
}
func valueToGoStringTensorsToSegmentationCalculator(v interface{}, typ string) string {
	rv := reflect.ValueOf(v)
	if rv.IsNil() {
		return "nil"
	}
	pv := reflect.Indirect(rv).Interface()
	return fmt.Sprintf("func(v %v) *%v { return &v } ( %#v )", typ, typ, pv)
}
func (m *TensorsToSegmentationCalculatorOptions) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *TensorsToSegmentationCalculatorOptions) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *TensorsToSegmentationCalculatorOptions) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.OutputLayerIndex != nil {
		i = encodeVarintTensorsToSegmentationCalculator(dAtA, i, uint64(*m.OutputLayerIndex))
		i--
		dAtA[i] = 0x18
	}
	if m.Activation != nil {
		i = encodeVarintTensorsToSegmentationCalculator(dAtA, i, uint64(*m.Activation))
		i--
		dAtA[i] = 0x10
	}
	i = encodeVarintTensorsToSegmentationCalculator(dAtA, i, uint64(m.GpuOrigin))
	i--
	dAtA[i] = 0x8
	return len(dAtA) - i, nil
}

func encodeVarintTensorsToSegmentationCalculator(dAtA []byte, offset int, v uint64) int {
	offset -= sovTensorsToSegmentationCalculator(v)
	base := offset
	for v >= 1<<7 {
		dAtA[offset] = uint8(v&0x7f | 0x80)
		v >>= 7
		offset++
	}
	dAtA[offset] = uint8(v)
	return base
}
func (m *TensorsToSegmentationCalculatorOptions) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	n += 1 + sovTensorsToSegmentationCalculator(uint64(m.GpuOrigin))
	if m.Activation != nil {
		n += 1 + sovTensorsToSegmentationCalculator(uint64(*m.Activation))
	}
	if m.OutputLayerIndex != nil {
		n += 1 + sovTensorsToSegmentationCalculator(uint64(*m.OutputLayerIndex))
	}
	return n
}

func sovTensorsToSegmentationCalculator(x uint64) (n int) {
	return (math_bits.Len64(x|1) + 6) / 7
}
func sozTensorsToSegmentationCalculator(x uint64) (n int) {
	return sovTensorsToSegmentationCalculator(uint64((x << 1) ^ uint64((int64(x) >> 63))))
}
func (this *TensorsToSegmentationCalculatorOptions) String() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&TensorsToSegmentationCalculatorOptions{`,
		`GpuOrigin:` + fmt.Sprintf("%v", this.GpuOrigin) + `,`,
		`Activation:` + valueToStringTensorsToSegmentationCalculator(this.Activation) + `,`,
		`OutputLayerIndex:` + valueToStringTensorsToSegmentationCalculator(this.OutputLayerIndex) + `,`,
		`}`,
	}, "")
	return s
}
func valueToStringTensorsToSegmentationCalculator(v interface{}) string {
	rv := reflect.ValueOf(v)
	if rv.IsNil() {
		return "nil"
	}
	pv := reflect.Indirect(rv).Interface()
	return fmt.Sprintf("*%v", pv)
}
func (m *TensorsToSegmentationCalculatorOptions) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowTensorsToSegmentationCalculator
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: TensorsToSegmentationCalculatorOptions: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: TensorsToSegmentationCalculatorOptions: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field GpuOrigin", wireType)
			}
			m.GpuOrigin = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowTensorsToSegmentationCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.GpuOrigin |= gpu.GpuOrigin_Mode(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Activation", wireType)
			}
			var v TensorsToSegmentationCalculatorOptions_Activation
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowTensorsToSegmentationCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= TensorsToSegmentationCalculatorOptions_Activation(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.Activation = &v
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field OutputLayerIndex", wireType)
			}
			var v int32
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowTensorsToSegmentationCalculator
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int32(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.OutputLayerIndex = &v
		default:
			iNdEx = preIndex
			skippy, err := skipTensorsToSegmentationCalculator(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthTensorsToSegmentationCalculator
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func skipTensorsToSegmentationCalculator(dAtA []byte) (n int, err error) {
	l := len(dAtA)
	iNdEx := 0
	depth := 0
	for iNdEx < l {
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return 0, ErrIntOverflowTensorsToSegmentationCalculator
			}
			if iNdEx >= l {
				return 0, io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		wireType := int(wire & 0x7)
		switch wireType {
		case 0:
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowTensorsToSegmentationCalculator
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				iNdEx++
				if dAtA[iNdEx-1] < 0x80 {
					break
				}
			}
		case 1:
			iNdEx += 8
		case 2:
			var length int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowTensorsToSegmentationCalculator
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				length |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if length < 0 {
				return 0, ErrInvalidLengthTensorsToSegmentationCalculator
			}
			iNdEx += length
		case 3:
			depth++
		case 4:
			if depth == 0 {
				return 0, ErrUnexpectedEndOfGroupTensorsToSegmentationCalculator
			}
			depth--
		case 5:
			iNdEx += 4
		default:
			return 0, fmt.Errorf("proto: illegal wireType %d", wireType)
		}
		if iNdEx < 0 {
			return 0, ErrInvalidLengthTensorsToSegmentationCalculator
		}
		if depth == 0 {
			return iNdEx, nil
		}
	}
	return 0, io.ErrUnexpectedEOF
}

var (
	ErrInvalidLengthTensorsToSegmentationCalculator        = fmt.Errorf("proto: negative length found during unmarshaling")
	ErrIntOverflowTensorsToSegmentationCalculator          = fmt.Errorf("proto: integer overflow")
	ErrUnexpectedEndOfGroupTensorsToSegmentationCalculator = fmt.Errorf("proto: unexpected end of group")
)
